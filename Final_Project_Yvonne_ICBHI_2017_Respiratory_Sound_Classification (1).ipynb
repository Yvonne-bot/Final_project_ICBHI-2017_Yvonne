{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, random, numpy as np, tensorflow as tf\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "import librosa, librosa.display\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from tensorflow.keras import layers as L, models as M, optimizers as O, callbacks as C\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "w22J07AdcsFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mF26EC-bTxUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/ICBHI_final_database.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/ICBHI_extracted')\n",
        "\n",
        "print(\" Extraction complete.\")"
      ],
      "metadata": {
        "id": "B4QRpa95uQ9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jp4RDjRs89P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/ICBHI_extracted/ICBHI_final_database'\n",
        "\n",
        "files = os.listdir(folder_path)\n",
        "print(f\"Total files found: {len(files)}\")\n",
        "\n",
        "annotation_files = [f for f in files if f.endswith('.txt')]\n",
        "audio_files = [f for f in files if f.endswith('.wav')]\n",
        "\n",
        "print(f\"Number of annotation files (.txt): {len(annotation_files)}\")\n",
        "print(f\"Number of audio files (.wav): {len(audio_files)}\")\n",
        "\n",
        "print(\"Sample annotation files:\", annotation_files[:5])\n",
        "print(\"Sample audio files:\", audio_files[:5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "annotation_bases = set(os.path.splitext(f)[0] for f in annotation_files)\n",
        "audio_bases = set(os.path.splitext(f)[0] for f in audio_files)\n",
        "\n",
        "missing_audio = annotation_bases - audio_bases\n",
        "\n",
        "print(f\"Annotation files without matching audio ({len(missing_audio)}):\")\n",
        "print(missing_audio)\n",
        "\n",
        "exclude_files = {'filename_format.txt', 'filename_differences.txt'}\n",
        "annotation_files = [f for f in annotation_files if f not in exclude_files]\n",
        "\n",
        "print(f\"Cleaned annotation files count: {len(annotation_files)}\")"
      ],
      "metadata": {
        "id": "L3oGGkiRuJU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = os.path.join(folder_path, '101_1b1_Al_sc_Meditron.txt')\n",
        "\n",
        "columns = ['start_time', 'end_time', 'crackles', 'wheezes']\n",
        "annotations_sample = pd.read_csv(file_path, sep='\\t', header=None, names=columns)\n",
        "\n",
        "print(annotations_sample)\n",
        "\n",
        "import librosa\n",
        "\n",
        "audio_file = file_path.replace('.txt', '.wav')\n",
        "\n",
        "audio, sr = librosa.load(audio_file, sr=None)\n",
        "\n",
        "duration = len(audio) / sr\n",
        "print(f\"Sample rate: {sr} Hz\")\n",
        "print(f\"Duration: {duration:.2f} seconds\")"
      ],
      "metadata": {
        "id": "k_KZwvCgvKBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "all_annotations = {}\n",
        "\n",
        "for ann_file in annotation_files:\n",
        "    ann_path = os.path.join(folder_path, ann_file)\n",
        "    columns = ['start_time', 'end_time', 'crackles', 'wheezes']\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(ann_path, sep='\\t', header=None, names=columns)\n",
        "        wav_file = ann_file.replace('.txt', '.wav')\n",
        "        all_annotations[wav_file] = df\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {ann_file}: {e}\")\n",
        "\n",
        "print(f\"Successfully loaded annotations for {len(all_annotations)} audio files.\")"
      ],
      "metadata": {
        "id": "qsexnaoGvrWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "audio_durations = {}\n",
        "\n",
        "for wav_file in audio_files:\n",
        "    wav_path = os.path.join(folder_path, wav_file)\n",
        "\n",
        "    try:\n",
        "        audio, sr = librosa.load(wav_path, sr=None)\n",
        "        duration = len(audio) / sr\n",
        "        audio_durations[wav_file] = duration\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {wav_file}: {e}\")\n",
        "\n",
        "print(f\"Got duration for {len(audio_durations)} audio files.\")\n",
        "\n",
        "for i, (name, dur) in enumerate(audio_durations.items()):\n",
        "    print(f\"{name}: {dur:.2f} seconds\")\n",
        "    if i >= 4: break\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "duration_df = pd.DataFrame(list(audio_durations.items()), columns=['filename', 'duration'])\n",
        "\n",
        "duration_df['duration_rounded'] = duration_df['duration'].round()\n",
        "\n",
        "print(\"Audio Duration Statistics:\")\n",
        "print(duration_df['duration'].describe())\n",
        "\n",
        "count_20s = (duration_df['duration_rounded'] == 20).sum()\n",
        "print(f\"\\nNumber of files exactly 20 seconds long: {count_20s}\")\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(duration_df['duration'], bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of Audio File Durations')\n",
        "plt.xlabel('Duration (seconds)')\n",
        "plt.ylabel('Number of files')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hovtp2UIvyuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0c2a501"
      },
      "source": [
        "import os\n",
        "import librosa\n",
        "from collections import Counter\n",
        "\n",
        "folder_path = '/content/ICBHI_extracted/ICBHI_final_database'\n",
        "\n",
        "sample_rate_counts = Counter()\n",
        "\n",
        "wav_files = [f for f in os.listdir(folder_path) if f.endswith('.wav')]\n",
        "\n",
        "for wav_file in wav_files:\n",
        "    wav_path = os.path.join(folder_path, wav_file)\n",
        "    try:\n",
        "        audio, sr = librosa.load(wav_path, sr=None)\n",
        "        sample_rate_counts[sr] += 1\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {wav_file}: {e}\")\n",
        "\n",
        "print(\"Sample rate distribution:\")\n",
        "for sr, count in sample_rate_counts.items():\n",
        "    print(f\"Sample rate {sr} Hz: {count} files\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "\n",
        "folder_path = '/content/ICBHI_extracted/ICBHI_final_database'\n",
        "\n",
        "example_file = list(all_annotations.keys())[0]\n",
        "\n",
        "example_annotation = all_annotations[example_file]\n",
        "\n",
        "example_path = os.path.join(folder_path, example_file)\n",
        "\n",
        "TARGET_SR = 16000\n",
        "\n",
        "audio, sr = librosa.load(example_path, sr=TARGET_SR)\n",
        "\n",
        "cycle_segments = []\n",
        "\n",
        "for idx, row in example_annotation.iterrows():\n",
        "    start_time = row['start_time']\n",
        "    end_time = row['end_time']\n",
        "\n",
        "    start_sample = int(start_time * sr)\n",
        "    end_sample = int(end_time * sr)\n",
        "\n",
        "    segment = audio[start_sample:end_sample]\n",
        "\n",
        "    cycle_segments.append({\n",
        "        'audio': segment,\n",
        "        'crackles': row['crackles'],\n",
        "        'wheezes': row['wheezes'],\n",
        "        'start_time': start_time,\n",
        "        'end_time': end_time\n",
        "    })\n",
        "\n",
        "print(f\"Extracted {len(cycle_segments)} respiratory cycles from: {example_file}\")"
      ],
      "metadata": {
        "id": "D1wOh2pcx2XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "\n",
        "folder_path = '/content/ICBHI_extracted/ICBHI_final_database'\n",
        "\n",
        "TARGET_SR = 16000\n",
        "\n",
        "all_segments = []\n",
        "\n",
        "for wav_file, annotation_df in all_annotations.items():\n",
        "    try:\n",
        "        wav_path = os.path.join(folder_path, wav_file)\n",
        "\n",
        "        audio, sr = librosa.load(wav_path, sr=TARGET_SR)\n",
        "\n",
        "        for idx, row in annotation_df.iterrows():\n",
        "            start_time = row['start_time']\n",
        "            end_time = row['end_time']\n",
        "\n",
        "            start_sample = int(start_time * sr)\n",
        "            end_sample = int(end_time * sr)\n",
        "\n",
        "            segment = audio[start_sample:end_sample]\n",
        "\n",
        "            all_segments.append({\n",
        "                'filename': wav_file,\n",
        "                'audio': segment,\n",
        "                'crackles': row['crackles'],\n",
        "                'wheezes': row['wheezes'],\n",
        "                'start_time': start_time,\n",
        "                'end_time': end_time,\n",
        "                'duration': end_time - start_time\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {wav_file}: {e}\")\n",
        "\n",
        "print(f\"Total respiratory cycles extracted: {len(all_segments)}\")"
      ],
      "metadata": {
        "id": "yNrBC8S_yLrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "FIXED_DURATION = 5.0\n",
        "FIXED_LENGTH = int(FIXED_DURATION * TARGET_SR)\n",
        "\n",
        "for segment_data in all_segments:\n",
        "    audio = segment_data['audio']\n",
        "    current_length = len(audio)\n",
        "\n",
        "    if current_length < FIXED_LENGTH:\n",
        "        pad_length = FIXED_LENGTH - current_length\n",
        "        padded_audio = np.pad(audio, (0, pad_length), mode='constant')\n",
        "        segment_data['audio'] = padded_audio\n",
        "\n",
        "    elif current_length > FIXED_LENGTH:\n",
        "        cropped_audio = audio[:FIXED_LENGTH]\n",
        "        segment_data['audio'] = cropped_audio\n",
        "\n",
        "\n",
        "print(f\"All segments cropped/padded to fixed length of {FIXED_DURATION} seconds ({FIXED_LENGTH} samples).\")"
      ],
      "metadata": {
        "id": "yMxiQQhfydEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "save_dir = '/content/ICBHI_extracted/ICBHI_final_database/processed_features'\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for segment_data in all_segments:\n",
        "    audio_clip = segment_data['audio']\n",
        "    mfcc = librosa.feature.mfcc(y=audio_clip, sr=sr, n_mfcc=13)\n",
        "    mfcc_mean = np.mean(mfcc, axis=1)\n",
        "\n",
        "    features.append(mfcc_mean)\n",
        "\n",
        "    multi_label = [segment_data['crackles'], segment_data['wheezes']]\n",
        "    labels.append(multi_label)\n",
        "\n",
        "features = np.array(features)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(f\"Features shape: {features.shape}\")\n",
        "print(f\"Labels shape: {labels.shape}\")\n",
        "\n",
        "\n",
        "np.save(os.path.join(save_dir, 'features.npy'), features)\n",
        "np.save(os.path.join(save_dir, 'labels.npy'), labels)\n",
        "\n",
        "print(f\" Features and labels saved to {save_dir}\")"
      ],
      "metadata": {
        "id": "gFcek82Rylw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "features_normalized = scaler.fit_transform(features)\n",
        "\n",
        "print(f\"Normalized features shape: {features_normalized.shape}\")\n",
        "\n",
        "print(\"Mean per feature (should be ~0):\", features_normalized.mean(axis=0))\n",
        "print(\"Std per feature (should be ~1):\", features_normalized.std(axis=0))\n",
        "\n",
        "save_dir = '/content/ICBHI_extracted/ICBHI_final_database/processed_features'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "scaler_path = os.path.join(save_dir, 'scaler.save')\n",
        "joblib.dump(scaler, scaler_path)\n",
        "\n",
        "print(f\"Scaler saved at: {scaler_path}\")"
      ],
      "metadata": {
        "id": "Gl_1CHF4zcym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    features_normalized, labels, test_size=0.3, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(\"Training set:\", X_train.shape, y_train.shape)\n",
        "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
        "print(\"Test set:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "ZczbW29yzl_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "mlp_model = Sequential([\n",
        "    Input(shape=(13,)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "mlp_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "mlp_history = mlp_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "y_train_pred_probs = mlp_model.predict(X_train)\n",
        "y_train_pred = (y_train_pred_probs > 0.5).astype(int)\n",
        "\n",
        "y_test_pred_probs = mlp_model.predict(X_test)\n",
        "y_test_pred = (y_test_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\" Classification Report - TRAIN\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['Crackles', 'Wheezes']))\n",
        "\n",
        "print(\" Classification Report - TEST\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['Crackles', 'Wheezes']))\n",
        "\n",
        "def plot_multilabel_cm(y_true, y_pred, labels, set_name):\n",
        "    cm = multilabel_confusion_matrix(y_true, y_pred)\n",
        "    for i, label in enumerate(labels):\n",
        "        plt.figure(figsize=(4, 3))\n",
        "        sns.heatmap(cm[i], annot=True, fmt='d', cmap='Blues', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "        plt.title(f'MLP Model Confusion Matrix for {label} ({set_name} Set)')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "labels_list = ['Crackles', 'Wheezes']\n",
        "plot_multilabel_cm(y_train, y_train_pred, labels_list, 'Train')\n",
        "plot_multilabel_cm(y_test, y_test_pred, labels_list, 'Test')"
      ],
      "metadata": {
        "id": "TZNjqXnwzstv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_curve, auc,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "SPLITS = {\n",
        "    \"Train\": (\"X_train\", \"y_train\"),\n",
        "    \"Val\":   (\"X_val\",   \"y_val\"),\n",
        "    \"Test\":  (\"X_test\",  \"y_test\"),\n",
        "}\n",
        "CLASS_NAMES = [\"Crackles\", \"Wheezes\"]\n",
        "THRESHOLD = 0.5\n",
        "DO_THRESHOLD_SWEEP = True\n",
        "\n",
        "CMAP_PURPLE = \"Purples\"\n",
        "FIGSIZE_CM = (5.5, 4.5)\n",
        "\n",
        "def get_var(name):\n",
        "    g = globals()\n",
        "    return g[name] if name in g else None\n",
        "\n",
        "def ensure_2d(y):\n",
        "    y = np.asarray(y)\n",
        "    if y.ndim == 1:\n",
        "        C = int(y.max()) + 1\n",
        "        Y = np.zeros((y.shape[0], C), dtype=int)\n",
        "        Y[np.arange(y.shape[0]), y] = 1\n",
        "        return Y\n",
        "    return y\n",
        "\n",
        "def keras_history_curves(history):\n",
        "    h = history.history if hasattr(history, \"history\") else history\n",
        "    if not isinstance(h, dict):\n",
        "        print(\"history not found or invalid; skipping curves.\")\n",
        "        return\n",
        "    plt.figure(figsize=(7,4))\n",
        "    if \"loss\" in h: plt.plot(h[\"loss\"], label=\"Train Loss\")\n",
        "    if \"val_loss\" in h: plt.plot(h[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.title(\"MLP Model Training & Validation Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "    acc_key = \"accuracy\" if \"accuracy\" in h else (\"acc\" if \"acc\" in h else None)\n",
        "    if acc_key:\n",
        "        plt.figure(figsize=(7,4))\n",
        "        plt.plot(h[acc_key], label=\"Train Acc (Keras)\")\n",
        "        if \"val_accuracy\" in h: plt.plot(h[\"val_accuracy\"], label=\"Val Acc (Keras)\")\n",
        "        plt.title(\"MLP Model Training & Validation Accuracy\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
        "        plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "def subset_accuracy(y_true, y_pred_bin):\n",
        "    return np.mean(np.all(y_true == y_pred_bin, axis=1))\n",
        "\n",
        "def per_label_accuracy(y_true, y_pred_bin):\n",
        "    return (y_true == y_pred_bin).mean(axis=0)\n",
        "\n",
        "def predict_proba(model, X):\n",
        "    proba = model.predict(X, verbose=0)\n",
        "    proba = np.asarray(proba)\n",
        "    if proba.ndim == 1:\n",
        "        proba = proba[:, None]\n",
        "    return proba\n",
        "\n",
        "def plot_confusion(cm, labels, title=\"Confusion Matrix\", normalize=False):\n",
        "    cm_plot = cm.astype(float)\n",
        "    if normalize:\n",
        "        with np.errstate(invalid=\"ignore\"):\n",
        "            row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
        "            cm_plot = np.divide(cm_plot, row_sums, out=np.zeros_like(cm_plot), where=row_sums!=0)\n",
        "    plt.figure(figsize=FIGSIZE_CM)\n",
        "    sns.heatmap(cm_plot, annot=True, fmt=\".2f\" if normalize else \".0f\",\n",
        "                cmap=CMAP_PURPLE, cbar=True,\n",
        "                xticklabels=[\"Neg\",\"Pos\"], yticklabels=[\"Neg\",\"Pos\"])\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "def plot_roc(y_true, y_proba, class_names, title_prefix=\"\"):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_proba = np.asarray(y_proba)\n",
        "    n_classes = y_true.shape[1]\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    aucs = []\n",
        "    for i in range(n_classes):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_proba[:, i])\n",
        "        A = auc(fpr, tpr)\n",
        "        aucs.append(A)\n",
        "        plt.plot(fpr, tpr, lw=1.5, label=f\"{class_names[i]} (AUC={A:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_true.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle=\"--\", lw=2, label=f\"micro-average (AUC={auc_micro:.3f})\")\n",
        "    plt.plot([0,1], [0,1], linestyle=\":\", color=\"gray\")\n",
        "    plt.title(f\"MLP Model {title_prefix} ROC Curves\")\n",
        "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\", fontsize=9)\n",
        "    plt.grid(True, alpha=0.3); plt.tight_layout(); plt.show()\n",
        "\n",
        "def evaluate_split(split_name, X, y, model, class_names, threshold=0.5):\n",
        "    X = np.asarray(X); y = ensure_2d(y)\n",
        "    y_proba = predict_proba(model, X)\n",
        "    if y_proba.shape[1] != y.shape[1]:\n",
        "        raise ValueError(f\"Predicted probs have shape {y_proba.shape}, but y has shape {y.shape}.\")\n",
        "    y_pred_bin = (y_proba >= threshold).astype(int)\n",
        "\n",
        "    keras_bin_acc = accuracy_score(y.flatten(), y_pred_bin.flatten())\n",
        "    subset_acc = subset_accuracy(y, y_pred_bin)\n",
        "    pla = per_label_accuracy(y, y_pred_bin)\n",
        "\n",
        "    print(f\"\\n=== MLP Model {split_name} Metrics (threshold={threshold:.2f}) ===\")\n",
        "    print(f\"Keras Binary Accuracy (overall): {keras_bin_acc:.4f}\")\n",
        "    print(f\"Subset Accuracy (exact match):  {subset_acc:.4f}\")\n",
        "    print(f\"Per-label Accuracy: \" + \", \".join([f\"{class_names[i]}={pla[i]:.4f}\" for i in range(len(class_names))]))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    for i, cname in enumerate(class_names):\n",
        "        print(f\"\\n-- {split_name} | {cname} --\")\n",
        "        print(classification_report(y[:, i], y_pred_bin[:, i], target_names=[\"No\",\"Yes\"], digits=3))\n",
        "\n",
        "    for i, cname in enumerate(class_names):\n",
        "        cm = confusion_matrix(y[:, i], y_pred_bin[:, i], labels=[0,1])\n",
        "        plot_confusion(cm, [\"No\",\"Yes\"], title=f\"MLP Model {split_name} {cname} — Confusion (Counts)\", normalize=False)\n",
        "        plot_confusion(cm, [\"No\",\"Yes\"], title=f\"MLP Model {split_name} {cname} — Confusion (Normalized)\", normalize=True)\n",
        "\n",
        "    plot_roc(y, y_proba, class_names, title_prefix=f\"{split_name}\")\n",
        "\n",
        "    return {\n",
        "        \"keras_binary_acc\": keras_bin_acc,\n",
        "        \"subset_acc\": subset_acc,\n",
        "        \"per_label_acc\": pla,\n",
        "    }\n",
        "\n",
        "def threshold_sweep(split_name, X, y, model, class_names, thresholds=np.linspace(0.2, 0.8, 13)):\n",
        "    X = np.asarray(X); y = ensure_2d(y)\n",
        "    y_proba = predict_proba(model, X)\n",
        "    best = {\"threshold\": None, \"subset_acc\": -1}\n",
        "    results = []\n",
        "    for t in thresholds:\n",
        "        y_pred_bin = (y_proba >= t).astype(int)\n",
        "        sa = subset_accuracy(y, y_pred_bin)\n",
        "        keras_bin_acc = accuracy_score(y.flatten(), y_pred_bin.flatten())\n",
        "        pla = per_label_accuracy(y, y_pred_bin)\n",
        "        results.append((t, sa, keras_bin_acc, *pla))\n",
        "        if sa > best[\"subset_acc\"]:\n",
        "            best = {\"threshold\": t, \"subset_acc\": sa}\n",
        "    results = np.array(results)\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(results[:,0], results[:,1], marker=\"o\", label=\"Subset Acc\")\n",
        "    plt.plot(results[:,0], results[:,2], marker=\"s\", label=\"Keras Binary Acc\")\n",
        "    for i, cname in enumerate(class_names):\n",
        "        plt.plot(results[:,0], results[:,3+i], marker=\".\", label=f\"Per-label Acc: {cname}\")\n",
        "    plt.title(f\"MLP Model {split_name} Threshold Sweep\")\n",
        "    plt.xlabel(\"Threshold\"); plt.ylabel(\"Accuracy\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    print(f\"Best subset-accuracy threshold for {split_name}: {best['threshold']:.2f} (subset_acc={best['subset_acc']:.4f})\")\n",
        "    return results\n",
        "\n",
        "_hist = get_var(\"mlp_history\") or get_var(\"hist\")\n",
        "if _hist is not None:\n",
        "    keras_history_curves(_hist)\n",
        "else:\n",
        "    print(\"No 'mlp_history' found; skipping training curves.\")\n",
        "\n",
        "summary = {}\n",
        "for split_name, (Xn, Yn) in SPLITS.items():\n",
        "    Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "    if Xv is None or Yv is None:\n",
        "        print(f\"{split_name}: missing split; skipping.\")\n",
        "        continue\n",
        "    summary[split_name] = evaluate_split(split_name, Xv, Yv, mlp_model, CLASS_NAMES, threshold=THRESHOLD)\n",
        "\n",
        "if DO_THRESHOLD_SWEEP:\n",
        "    for split_name, (Xn, Yn) in SPLITS.items():\n",
        "        Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "        if Xv is None or Yv is None:\n",
        "            continue\n",
        "        print(f\"\\nThreshold sweep on {split_name}:\")\n",
        "        threshold_sweep(split_name, Xv, Yv, mlp_model, CLASS_NAMES)"
      ],
      "metadata": {
        "id": "u677XfQy0ApW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "def multilabel_to_single(y_bin):\n",
        "    return y_bin[:, 0]*1 + y_bin[:, 1]*2\n",
        "\n",
        "def plot_full_class_confusion(y_true_bin, y_pred_bin, split_name=\"\"):\n",
        "    y_true_single = multilabel_to_single(y_true_bin)\n",
        "    y_pred_single = multilabel_to_single(y_pred_bin)\n",
        "    cm_full = confusion_matrix(y_true_single, y_pred_single, labels=[0, 1, 2, 3])\n",
        "    class_labels = [\"Normal\", \"Crackles\", \"Wheezes\", \"Both\"]\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm_full, annot=True, fmt=\"d\", cmap=\"Purples\",\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.title(f\"{split_name} — Confusion Matrix (4-Class View)\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return cm_full\n",
        "\n",
        "for split_name, (Xn, Yn) in SPLITS.items():\n",
        "    Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "    if Xv is None or Yv is None:\n",
        "        continue\n",
        "    y_true = ensure_2d(Yv)\n",
        "    y_proba = predict_proba(mlp_model, Xv)\n",
        "    y_pred_bin = (y_proba >= THRESHOLD).astype(int)\n",
        "    plot_full_class_confusion(y_true, y_pred_bin, split_name=split_name)"
      ],
      "metadata": {
        "id": "tb8h_TYg2IkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "767e6028"
      },
      "source": [
        "### MLP Model Summary of Findings\n",
        "\n",
        "Here is a summary of the MLP model's performance on the training and test sets:\n",
        "\n",
        "| Metric                     | Train Set (Overall) | Test Set (Overall) | Crackles (Train) | Wheezes (Train) | Crackles (Test) | Wheezes (Test) |\n",
        "|----------------------------|---------------------|--------------------|------------------|-----------------|-----------------|----------------|\n",
        "| Keras Binary Accuracy      | 0.7814              | 0.7734             | -                | -               | -               | -              |\n",
        "| Subset Accuracy            | 0.6087              | 0.6097             | -                | -               | -               | -              |\n",
        "| Loss (Final Epoch)         | 0.4896              | 0.4961             | -                | -               | -               | -              |\n",
        "| Precision                  | -                   | -                  | 0.664            | 0.873           | 0.607           | 0.844          |\n",
        "| Recall                     | -                   | -                  | 0.507            | 0.143           | 0.489           | 0.122          |\n",
        "| F1-Score                   | -                   | -                  | 0.575            | 0.246           | 0.542           | 0.213          |\n",
        "\n",
        "**Key Observations:**\n",
        "\n",
        "*   The overall accuracy metrics (Keras Binary Accuracy and Subset Accuracy) are relatively similar between the train and test sets, suggesting the model is not significantly overfitting the training data.\n",
        "*   The model shows a large disparity in performance between the 'Crackles' and 'Wheezes' classes.\n",
        "*   'Crackles' detection has a more balanced precision and recall, indicating a moderate ability to correctly identify this class.\n",
        "*   'Wheezes' detection has very low recall on both sets, meaning the model is failing to identify a large proportion of actual wheezes. The high precision for wheezes is misleading due to the low number of positive predictions.\n",
        "*   The loss on the validation set is slightly higher than the training loss, but the values are close, which again suggests no major overfitting.\n",
        "\n",
        "This summary highlights the challenge in detecting the 'Wheezes' class, which should be the focus of future model improvements."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "segment_audio = all_segments[0]['audio']\n",
        "sample_rate = 44100\n",
        "\n",
        "def extract_mel_spectrogram(audio_segment, sr, n_mels=128, fmax=8000):\n",
        "    S = librosa.feature.melspectrogram(y=audio_segment, sr=sr, n_mels=n_mels, fmax=fmax)\n",
        "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "    return S_dB\n",
        "\n",
        "mel_spec = extract_mel_spectrogram(segment_audio, sample_rate)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mel_spec, sr=sample_rate, x_axis='time', y_axis='mel', fmax=8000)\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel Spectrogram (dB)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "import random\n",
        "\n",
        "crackle_indices = [i for i, seg in enumerate(all_segments) if seg['crackles'] == 1]\n",
        "wheeze_indices = [i for i, seg in enumerate(all_segments) if seg['wheezes'] == 1]\n",
        "\n",
        "if crackle_indices:\n",
        "    idx_crackle = random.choice(crackle_indices)\n",
        "    segment_crackle = all_segments[idx_crackle]['audio']\n",
        "    print(f\"Visualizing crackle segment from file: {all_segments[idx_crackle]['filename']}\")\n",
        "\n",
        "    mel_spec_crackle = extract_mel_spectrogram(segment_crackle, sample_rate)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(mel_spec_crackle, sr=sample_rate, x_axis='time', y_axis='mel', fmax=8000)\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Mel Spectrogram - Crackle Segment')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No crackle segments found!\")\n",
        "\n",
        "if wheeze_indices:\n",
        "    idx_wheeze = random.choice(wheeze_indices)\n",
        "    segment_wheeze = all_segments[idx_wheeze]['audio']\n",
        "    print(f\"Visualizing wheeze segment from file: {all_segments[idx_wheeze]['filename']}\")\n",
        "\n",
        "    mel_spec_wheeze = extract_mel_spectrogram(segment_wheeze, sample_rate)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(mel_spec_wheeze, sr=sample_rate, x_axis='time', y_axis='mel', fmax=8000)\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('Mel Spectrogram - Wheeze Segment')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No wheeze segments found!\")"
      ],
      "metadata": {
        "id": "xbe4R4zf17HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "n_mels = 128\n",
        "fmax = 8000\n",
        "sr = 16000\n",
        "hop_length = 512\n",
        "\n",
        "mel_specs = []\n",
        "labels = []\n",
        "\n",
        "for i, segment in enumerate(tqdm(all_segments)):\n",
        "    audio = segment['audio']\n",
        "\n",
        "    mel = librosa.feature.melspectrogram(\n",
        "        y=audio, sr=sr, n_mels=n_mels, fmax=fmax, hop_length=hop_length\n",
        "    )\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "    mel_db = (mel_db - mel_db.mean()) / (mel_db.std() + 1e-6)\n",
        "\n",
        "    mel_specs.append(mel_db)\n",
        "\n",
        "    labels.append([segment['crackles'], segment['wheezes']])\n",
        "\n",
        "try:\n",
        "    mel_specs = np.array(mel_specs)\n",
        "    print(\" Mel spectrograms shape:\", mel_specs.shape)\n",
        "except ValueError as e:\n",
        "    print(f\"Error converting mel_specs to numpy array: {e}\")\n",
        "    first_shape = mel_specs[0].shape if len(mel_specs) > 0 else None\n",
        "    if first_shape:\n",
        "        print(\"Checking for inconsistent shapes...\")\n",
        "        for j in range(len(mel_specs)):\n",
        "            if mel_specs[j].shape != first_shape:\n",
        "                print(f\"Inconsistent shape at index {j}: {mel_specs[j].shape} (expected {first_shape})\")\n",
        "\n",
        "\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\" Labels shape:\", labels.shape)\n",
        "\n",
        "save_dir = '/content/ICBHI_extracted/ICBHI_final_database/processed_features'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "np.save(os.path.join(save_dir, 'mel_spectrograms.npy'), mel_specs)\n",
        "np.save(os.path.join(save_dir, 'labels.npy'), labels)\n",
        "\n",
        "print(f\" Saved mel spectrograms and labels to {save_dir}\")"
      ],
      "metadata": {
        "id": "E_PpDnVp28DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data_dir = '/content/ICBHI_extracted/ICBHI_final_database/processed_features'\n",
        "X = np.load(os.path.join(data_dir, 'mel_spectrograms.npy'))\n",
        "y = np.load(os.path.join(data_dir, 'labels.npy'))\n",
        "\n",
        "X = X[..., np.newaxis]\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, shuffle=True)\n",
        "\n",
        "model = Sequential([\n",
        "    InputLayer(input_shape=(128, 157, 1)),\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_path = os.path.join(data_dir, 'cnn_mel_model.h5')\n",
        "model.save(model_path)\n",
        "print(f\" CNN model saved to: {model_path}\")\n",
        "\n",
        "y_train_pred_probs = model.predict(X_train)\n",
        "y_train_pred = (y_train_pred_probs > 0.5).astype(int)\n",
        "\n",
        "y_test_pred_probs = model.predict(X_test)\n",
        "y_test_pred = (y_test_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\" Classification Report - TRAIN\")\n",
        "print(classification_report(y_train, y_train_pred, target_names=['Crackles', 'Wheezes']))\n",
        "\n",
        "print(\" Classification Report - TEST\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['Crackles', 'Wheezes']))\n",
        "\n",
        "def plot_multilabel_cm(y_true, y_pred, labels, set_name):\n",
        "    cm = multilabel_confusion_matrix(y_true, y_pred)\n",
        "    for i, label in enumerate(labels):\n",
        "        plt.figure(figsize=(4, 3))\n",
        "        sns.heatmap(cm[i], annot=True, fmt='d', cmap='Blues',\n",
        "                    xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "        plt.title(f'Confusion Matrix for {label} ({set_name} Set)')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "labels_list = ['Crackles', 'Wheezes']\n",
        "plot_multilabel_cm(y_train, y_train_pred, labels_list, 'Train')\n",
        "plot_multilabel_cm(y_test, y_test_pred, labels_list, 'Test')"
      ],
      "metadata": {
        "id": "dzyS68Ju3GWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_curve, auc,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "CMAP_PURPLE = \"Purples\"\n",
        "FIGSIZE_CM = (5.5, 4.5)\n",
        "CLASS_NAMES = [\"Crackles\", \"Wheezes\"]\n",
        "THRESHOLD = 0.5\n",
        "DO_THRESHOLD_SWEEP = True\n",
        "\n",
        "def plot_training_curves(history):\n",
        "    h = history.history\n",
        "    if \"loss\" in h:\n",
        "        plt.figure(figsize=(7, 4))\n",
        "        plt.plot(h[\"loss\"], label=\"Train Loss\")\n",
        "        if \"val_loss\" in h:\n",
        "            plt.plot(h[\"val_loss\"], label=\"Val Loss\")\n",
        "        plt.title(\"Training & Validation Loss\")\n",
        "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend(); plt.tight_layout(); plt.show()\n",
        "    if \"accuracy\" in h:\n",
        "        plt.figure(figsize=(7, 4))\n",
        "        plt.plot(h[\"accuracy\"], label=\"Train Accuracy\")\n",
        "        if \"val_accuracy\" in h:\n",
        "            plt.plot(h[\"val_accuracy\"], label=\"Val Accuracy\")\n",
        "        plt.title(\"Training & Validation Accuracy\")\n",
        "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_confusion(cm, title=\"Confusion Matrix\", normalize=False):\n",
        "    cm = np.asarray(cm, dtype=float)\n",
        "    if normalize:\n",
        "        with np.errstate(invalid='ignore'):\n",
        "            cm_sum = cm.sum(axis=1, keepdims=True)\n",
        "            cm = np.divide(cm, cm_sum, out=np.zeros_like(cm), where=cm_sum!=0)\n",
        "        fmt = \".2f\"\n",
        "    else:\n",
        "        fmt = \".0f\"\n",
        "    plt.figure(figsize=FIGSIZE_CM)\n",
        "    sns.heatmap(cm, annot=True, fmt=fmt, cmap=CMAP_PURPLE,\n",
        "                xticklabels=[\"No\", \"Yes\"], yticklabels=[\"No\", \"Yes\"])\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "def plot_roc_curves(y_true, y_proba, class_names, title_prefix=\"\"):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_proba = np.asarray(y_proba)\n",
        "    n_classes = y_true.shape[1]\n",
        "\n",
        "    plt.figure(figsize=(7, 6))\n",
        "    for i in range(n_classes):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_proba[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, label=f\"{class_names[i]} (AUC = {roc_auc:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_true.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle='--', lw=2, label=f\"Micro-average (AUC = {auc_micro:.3f})\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\":\", color=\"gray\")\n",
        "    plt.title(f\"{title_prefix} ROC Curves\")\n",
        "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def get_4class_labels(y):\n",
        "    return np.array([\n",
        "        0 if (a == 0 and b == 0) else\n",
        "        1 if (a == 1 and b == 0) else\n",
        "        2 if (a == 0 and b == 1) else\n",
        "        3 for a, b in y\n",
        "    ])\n",
        "\n",
        "def evaluate_model(X, y_true, model, history, class_names, split_name=\"Test\", threshold=0.5):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_proba = model.predict(X, verbose=0)\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "    keras_bin_acc = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "    subset_acc = np.mean(np.all(y_true == y_pred, axis=1))\n",
        "    per_label_acc = (y_true == y_pred).mean(axis=0)\n",
        "\n",
        "    print(f\"\\n=== {split_name} Metrics (threshold={threshold:.2f}) ===\")\n",
        "    print(f\"Binary Accuracy (flattened): {keras_bin_acc:.4f}\")\n",
        "    print(f\"Subset Accuracy (exact match): {subset_acc:.4f}\")\n",
        "    print(\"Per-label Accuracy:\")\n",
        "    for i, name in enumerate(class_names):\n",
        "        print(f\" - {name}: {per_label_acc[i]:.4f}\")\n",
        "\n",
        "    for i, cname in enumerate(class_names):\n",
        "        print(f\"\\n-- {split_name} Classification Report: {cname} --\")\n",
        "        print(classification_report(y_true[:, i], y_pred[:, i], target_names=[\"No\", \"Yes\"]))\n",
        "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
        "        plot_confusion(cm, f\"{split_name} Confusion Matrix - {cname} (Counts)\", normalize=False)\n",
        "        plot_confusion(cm, f\"{split_name} Confusion Matrix - {cname} (Normalized)\", normalize=True)\n",
        "\n",
        "    plot_roc_curves(y_true, y_proba, class_names, title_prefix=split_name)\n",
        "\n",
        "    y_true_4 = get_4class_labels(y_true)\n",
        "    y_pred_4 = get_4class_labels(y_pred)\n",
        "    cm_4class = confusion_matrix(y_true_4, y_pred_4)\n",
        "    labels_4 = [\"Normal\", \"Crackles\", \"Wheezes\", \"Both\"]\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm_4class, annot=True, fmt='d', cmap=\"Purples\",\n",
        "                xticklabels=labels_4, yticklabels=labels_4)\n",
        "    plt.title(f\"{split_name} Confusion Matrix — 4-Class View\")\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "evaluate_model(X_test, y_test, model, history, CLASS_NAMES, split_name=\"Test\")"
      ],
      "metadata": {
        "id": "R9mikHuD3zao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d1cd5fe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_curve, auc,\n",
        "    accuracy_score, multilabel_confusion_matrix\n",
        ")\n",
        "\n",
        "cnn_model = model\n",
        "\n",
        "SPLITS = {\n",
        "    \"Train\": (\"X_train\", \"y_train\"),\n",
        "    \"Val\":   (\"X_val\",   \"y_val\"),\n",
        "    \"Test\":  (\"X_test\",  \"y_test\"),\n",
        "}\n",
        "CLASS_NAMES = [\"Crackles\", \"Wheezes\"]\n",
        "THRESHOLD = 0.5\n",
        "DO_THRESHOLD_SWEEP = True\n",
        "\n",
        "CMAP_BLUES = \"Blues\"\n",
        "FIGSIZE_CM = (5.5, 4.5)\n",
        "\n",
        "def get_var(name):\n",
        "    g = globals()\n",
        "    return g[name] if name in g else None\n",
        "\n",
        "def ensure_2d(y):\n",
        "    y = np.asarray(y)\n",
        "    if y.ndim == 1:\n",
        "        C = int(y.max()) + 1\n",
        "        Y = np.zeros((y.shape[0], C), dtype=int)\n",
        "        Y[np.arange(y.shape[0]), y] = 1\n",
        "        return Y\n",
        "    return y\n",
        "\n",
        "def keras_history_curves_cnn(history):\n",
        "    h = history.history if hasattr(history, \"history\") else history\n",
        "    if not isinstance(h, dict):\n",
        "        print(\"history not found or invalid; skipping curves.\")\n",
        "        return\n",
        "    plt.figure(figsize=(7,4))\n",
        "    if \"loss\" in h: plt.plot(h[\"loss\"], label=\"Train Loss\")\n",
        "    if \"val_loss\" in h: plt.plot(h[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.title(\"CNN Model Training & Validation Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "    acc_key = \"accuracy\" if \"accuracy\" in h else (\"acc\" if \"acc\" in h else None)\n",
        "    if acc_key:\n",
        "        plt.figure(figsize=(7,4))\n",
        "        plt.plot(h[acc_key], label=\"Train Acc (Keras)\")\n",
        "        if \"val_accuracy\" in h: plt.plot(h[\"val_accuracy\"], label=\"Val Acc (Keras)\")\n",
        "        plt.title(\"CNN Model Training & Validation Accuracy\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\")\n",
        "        plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "def subset_accuracy(y_true, y_pred_bin):\n",
        "    return np.mean(np.all(y_true == y_pred_bin, axis=1))\n",
        "\n",
        "def per_label_accuracy(y_true, y_pred_bin):\n",
        "    return (y_true == y_pred_bin).mean(axis=0)\n",
        "\n",
        "def predict_proba_cnn(model, X):\n",
        "    proba = model.predict(X, verbose=0)\n",
        "    proba = np.asarray(proba)\n",
        "    if proba.ndim == 1:\n",
        "        proba = proba[:, None]\n",
        "    return proba\n",
        "\n",
        "def plot_confusion_cnn(cm, labels, title=\"Confusion Matrix\", normalize=False):\n",
        "    cm_plot = cm.astype(float)\n",
        "    if normalize:\n",
        "        with np.errstate(invalid=\"ignore\"):\n",
        "            row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
        "            cm_plot = np.divide(cm_plot, row_sums, out=np.zeros_like(cm_plot), where=row_sums!=0)\n",
        "    plt.figure(figsize=FIGSIZE_CM)\n",
        "    sns.heatmap(cm_plot, annot=True, fmt=\".2f\" if normalize else \".0f\",\n",
        "                cmap=CMAP_BLUES, cbar=True,\n",
        "                xticklabels=[\"Neg\",\"Pos\"], yticklabels=[\"Neg\",\"Pos\"])\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "def plot_roc_cnn(y_true, y_proba, class_names, title_prefix=\"\"):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_proba = np.asarray(y_proba)\n",
        "    n_classes = y_true.shape[1]\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    aucs = []\n",
        "    for i in range(n_classes):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_proba[:, i])\n",
        "        A = auc(fpr, tpr)\n",
        "        aucs.append(A)\n",
        "        plt.plot(fpr, tpr, lw=1.5, label=f\"{class_names[i]} (AUC={A:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_true.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle=\"--\", lw=2, label=f\"micro-average (AUC={auc_micro:.3f})\")\n",
        "    plt.plot([0,1], [0,1], linestyle=\":\", color=\"gray\")\n",
        "    plt.title(f\"CNN Model {title_prefix} ROC Curves\")\n",
        "    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "    plt.legend(loc=\"lower right\", fontsize=9)\n",
        "    plt.grid(True, alpha=0.3); plt.tight_layout(); plt.show()\n",
        "\n",
        "def evaluate_split_cnn(split_name, X, y, model, class_names, threshold=0.5):\n",
        "    X = np.asarray(X); y = ensure_2d(y)\n",
        "    y_proba = predict_proba_cnn(model, X)\n",
        "    if y_proba.shape[1] != y.shape[1]:\n",
        "        raise ValueError(f\"Predicted probs have shape {y_proba.shape}, but y has shape {y.shape}.\")\n",
        "    y_pred_bin = (y_proba >= threshold).astype(int)\n",
        "\n",
        "    keras_bin_acc = accuracy_score(y.flatten(), y_pred_bin.flatten())\n",
        "    subset_acc = subset_accuracy(y, y_pred_bin)\n",
        "    pla = per_label_accuracy(y, y_pred_bin)\n",
        "\n",
        "    print(f\"\\n=== CNN Model {split_name} Metrics (threshold={threshold:.2f}) ===\")\n",
        "    print(f\"Keras Binary Accuracy (overall): {keras_bin_acc:.4f}\")\n",
        "    print(f\"Subset Accuracy (exact match):  {subset_acc:.4f}\")\n",
        "    print(f\"Per-label Accuracy: \" + \", \".join([f\"{class_names[i]}={pla[i]:.4f}\" for i in range(len(class_names))]))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    for i, cname in enumerate(class_names):\n",
        "        print(f\"\\n-- {split_name} | {cname} --\")\n",
        "        print(classification_report(y[:, i], y_pred_bin[:, i], target_names=[\"No\",\"Yes\"], digits=3))\n",
        "\n",
        "    for i, cname in enumerate(class_names):\n",
        "        cm = confusion_matrix(y[:, i], y_pred_bin[:, i], labels=[0,1])\n",
        "        plot_confusion_cnn(cm, [\"No\",\"Yes\"], title=f\"CNN Model {split_name} {cname} — Confusion (Counts)\", normalize=False)\n",
        "        plot_confusion_cnn(cm, [\"No\",\"Yes\"], title=f\"CNN Model {split_name} {cname} — Confusion (Normalized)\", normalize=True)\n",
        "\n",
        "    plot_roc_cnn(y, y_proba, class_names, title_prefix=f\"{split_name}\")\n",
        "\n",
        "    return {\n",
        "        \"keras_binary_acc\": keras_bin_acc,\n",
        "        \"subset_acc\": subset_acc,\n",
        "        \"per_label_acc\": pla,\n",
        "    }\n",
        "\n",
        "def threshold_sweep_cnn(split_name, X, y, model, class_names, thresholds=np.linspace(0.2, 0.8, 13)):\n",
        "    X = np.asarray(X); y = ensure_2d(y)\n",
        "    y_proba = predict_proba_cnn(model, X)\n",
        "    best = {\"threshold\": None, \"subset_acc\": -1}\n",
        "    results = []\n",
        "    for t in thresholds:\n",
        "        y_pred_bin = (y_proba >= t).astype(int)\n",
        "        sa = subset_accuracy(y, y_pred_bin)\n",
        "        keras_bin_acc = accuracy_score(y.flatten(), y_pred_bin.flatten())\n",
        "        pla = per_label_accuracy(y, y_pred_bin)\n",
        "        results.append((t, sa, keras_bin_acc, *pla))\n",
        "        if sa > best[\"subset_acc\"]:\n",
        "            best = {\"threshold\": t, \"subset_acc\": sa}\n",
        "    results = np.array(results)\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(results[:,0], results[:,1], marker=\"o\", label=\"Subset Acc\")\n",
        "    plt.plot(results[:,0], results[:,2], marker=\"s\", label=\"Keras Binary Acc\")\n",
        "    for i, cname in enumerate(class_names):\n",
        "        plt.plot(results[:,0], results[:,3+i], marker=\".\", label=f\"Per-label Acc: {cname}\")\n",
        "    plt.title(f\"CNN Model {split_name} Threshold Sweep\")\n",
        "    plt.xlabel(\"Threshold\"); plt.ylabel(\"Accuracy\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    print(f\"Best subset-accuracy threshold for {split_name}: {best['threshold']:.2f} (subset_acc={best['subset_acc']:.4f})\")\n",
        "    return results\n",
        "\n",
        "def get_4class_labels(y):\n",
        "    return np.array([\n",
        "        0 if (a == 0 and b == 0) else\n",
        "        1 if (a == 1 and b == 0) else\n",
        "        2 if (a == 0 and b == 1) else\n",
        "        3 for a, b in y\n",
        "    ])\n",
        "\n",
        "def plot_full_class_confusion_cnn(y_true_bin, y_pred_bin, split_name=\"\"):\n",
        "    y_true_single = get_4class_labels(y_true_bin)\n",
        "    y_pred_single = get_4class_labels(y_pred_bin)\n",
        "    cm_full = confusion_matrix(y_true_single, y_pred_single, labels=[0, 1, 2, 3])\n",
        "    class_labels = [\"Normal\", \"Crackles\", \"Wheezes\", \"Both\"]\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm_full, annot=True, fmt=\"d\", cmap=CMAP_BLUES,\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.title(f\"CNN Model {split_name} — Confusion Matrix (4-Class View)\")\n",
        "    plt.xlabel(\"Predicted Label\"); plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "    return cm_full\n",
        "\n",
        "\n",
        "cnn_history = get_var(\"history\")\n",
        "if cnn_history is not None:\n",
        "    keras_history_curves_cnn(cnn_history)\n",
        "else:\n",
        "    print(\"No 'history' found for CNN; skipping training curves.\")\n",
        "\n",
        "cnn_summary = {}\n",
        "for split_name, (Xn, Yn) in SPLITS.items():\n",
        "    Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "    if Xv is None or Yv is None:\n",
        "        print(f\"{split_name}: missing split; skipping.\")\n",
        "        continue\n",
        "    if split_name == \"Train\":\n",
        "        cnn_summary[split_name] = evaluate_split_cnn(split_name, X_train, y_train, cnn_model, CLASS_NAMES, threshold=THRESHOLD)\n",
        "    elif split_name == \"Val\":\n",
        "        cnn_summary[split_name] = evaluate_split_cnn(split_name, X_val, y_val, cnn_model, CLASS_NAMES, threshold=THRESHOLD)\n",
        "    elif split_name == \"Test\":\n",
        "        cnn_summary[split_name] = evaluate_split_cnn(split_name, X_test, y_test, cnn_model, CLASS_NAMES, threshold=THRESHOLD)\n",
        "\n",
        "\n",
        "if DO_THRESHOLD_SWEEP:\n",
        "    for split_name, (Xn, Yn) in SPLITS.items():\n",
        "        Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "        if Xv is None or Yv is None:\n",
        "            continue\n",
        "        print(f\"\\nThreshold sweep on {split_name} for CNN:\")\n",
        "        if split_name == \"Train\":\n",
        "             threshold_sweep_cnn(split_name, X_train, y_train, cnn_model, CLASS_NAMES)\n",
        "        elif split_name == \"Val\":\n",
        "             threshold_sweep_cnn(split_name, X_val, y_val, cnn_model, CLASS_NAMES)\n",
        "        elif split_name == \"Test\":\n",
        "             threshold_sweep_cnn(split_name, X_test, y_test, cnn_model, CLASS_NAMES)\n",
        "\n",
        "\n",
        "print(\"\\n4-Class Confusion Matrices for CNN:\")\n",
        "for split_name, (Xn, Yn) in SPLITS.items():\n",
        "    Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "    if Xv is None or Yv is None:\n",
        "        continue\n",
        "    y_true = ensure_2d(Yv)\n",
        "    if split_name == \"Train\":\n",
        "        y_proba = predict_proba_cnn(cnn_model, X_train)\n",
        "        y_pred_bin = (y_proba >= THRESHOLD).astype(int)\n",
        "        plot_full_class_confusion_cnn(y_train, y_pred_bin, split_name=split_name)\n",
        "    elif split_name == \"Val\":\n",
        "        y_proba = predict_proba_cnn(cnn_model, X_val)\n",
        "        y_pred_bin = (y_proba >= THRESHOLD).astype(int)\n",
        "        plot_full_class_confusion_cnn(y_val, y_pred_bin, split_name=split_name)\n",
        "    elif split_name == \"Test\":\n",
        "        y_proba = predict_proba_cnn(cnn_model, X_test)\n",
        "        y_test_pred_bin = (y_proba >= THRESHOLD).astype(int) # Define y_test_pred_bin here\n",
        "        plot_full_class_confusion_cnn(y_test, y_test_pred_bin, split_name=split_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1341a536"
      },
      "source": [
        "### CNN Model Summary of Findings\n",
        "\n",
        "Here is a summary of the CNN model's performance on the training and test sets:\n",
        "\n",
        "| Metric                     | Train Set (Overall) | Test Set (Overall) | Crackles (Train) | Wheezes (Train) | Crackles (Test) | Wheezes (Test) |\n",
        "|----------------------------|---------------------|--------------------|------------------|-----------------|-----------------|----------------|\n",
        "| Keras Binary Accuracy      | 0.8820              | 0.7889             | -                | -               | -               | -              |\n",
        "| Subset Accuracy            | 0.7817              | 0.6357             | -                | -               | -               | -              |\n",
        "| Loss (Final Epoch)         | 0.2641              | 0.5093             | -                | -               | -               | -              |\n",
        "| Precision                  | -                   | -                  | 0.830            | 0.925           | 0.618           | 0.667          |\n",
        "| Recall                     | -                   | -                  | 0.740            | 0.586           | 0.538           | 0.387          |\n",
        "| F1-Score                   | -                   | -                  | 0.783            | 0.717           | 0.576            | 0.490          |\n",
        "\n",
        "**Key Observations:**\n",
        "\n",
        "*   The CNN model shows higher training accuracy and lower training loss compared to the MLP model, indicating it learned the training data more effectively.\n",
        "*   There is a noticeable drop in performance from the training set to the test set for the CNN, particularly in accuracy and F1-score, suggesting some degree of overfitting to the training data.\n",
        "*   For 'Crackles', the CNN model shows improved recall on the test set (0.54) compared to the MLP (0.49), while maintaining similar precision.\n",
        "*   For 'Wheezes', the CNN model demonstrates significantly better recall on the test set (0.39) compared to the MLP (0.12), although it's still relatively low. The precision for Wheezes is also lower on the test set (0.67) compared to the train set (0.925), indicating more false positives on unseen data.\n",
        "*   The 4-class confusion matrix provides a more detailed view of how the CNN is classifying the different combinations of crackles and wheezes.\n",
        "\n",
        "Overall, the CNN model appears to capture more complex patterns in the data, leading to better recall for both classes, especially 'Wheezes', compared to the simpler MLP model. However, addressing the overfitting and further improving the detection of 'Wheezes' remain important areas for improvement."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, TimeDistributed, LSTM, Dense, Reshape, InputLayer\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data_dir = '/content/ICBHI_extracted/ICBHI_final_database/processed_features'\n",
        "X = np.load(os.path.join(data_dir, 'mel_spectrograms.npy'))\n",
        "y = np.load(os.path.join(data_dir, 'labels.npy'))\n",
        "\n",
        "X = X[..., np.newaxis]\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, shuffle=True)\n",
        "\n",
        "model = Sequential([\n",
        "    InputLayer(input_shape=(128, 157, 1)),\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Reshape((32, -1)),\n",
        "\n",
        "    LSTM(64, return_sequences=False),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_path = os.path.join(data_dir, 'cnn_lstm_model.h5')\n",
        "model.save(model_path)\n",
        "print(f\" CNN-LSTM model saved to: {model_path}\")\n",
        "\n",
        "y_test_pred_probs = model.predict(X_test)\n",
        "y_test_pred = (y_test_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\" Classification Report - TEST\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['Crackles', 'Wheezes']))\n",
        "\n",
        "cm_test = multilabel_confusion_matrix(y_test, y_test_pred)\n",
        "labels_list = ['Crackles', 'Wheezes']\n",
        "\n",
        "for i, label in enumerate(labels_list):\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    sns.heatmap(cm_test[i], annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "    plt.title(f'Confusion Matrix - {label}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "7oxf_JMn5U_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_curve, auc,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "CMAP_PURPLE = \"Purples\"\n",
        "FIGSIZE_CM = (5.5, 4.5)\n",
        "CLASS_NAMES = [\"Crackles\", \"Wheezes\"]\n",
        "THRESHOLD = 0.5\n",
        "DO_THRESHOLD_SWEEP = True\n",
        "\n",
        "def plot_history(history):\n",
        "    h = history.history if hasattr(history, \"history\") else history\n",
        "    if not isinstance(h, dict):\n",
        "        print(\"history not found or invalid; skipping curves.\")\n",
        "        return\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    if \"loss\" in h: plt.plot(h[\"loss\"], label=\"Train Loss\")\n",
        "    if \"val_loss\" in h: plt.plot(h[\"val_loss\"], label=\"Val Loss\")\n",
        "    plt.title(\"Training & Validation Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(h.get('accuracy', []), label='Train Acc')\n",
        "    plt.plot(h.get('val_accuracy', []), label='Val Acc')\n",
        "    plt.title('Training & Validation Accuracy')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_confusion(cm, title=\"Confusion Matrix\", normalize=False):\n",
        "    cm = np.asarray(cm, dtype=float)\n",
        "    if normalize:\n",
        "        with np.errstate(invalid='ignore'):\n",
        "            row_sum = cm.sum(axis=1, keepdims=True)\n",
        "            cm = np.divide(cm, row_sum, out=np.zeros_like(cm), where=row_sum != 0)\n",
        "        fmt = \".2f\"\n",
        "    else:\n",
        "        fmt = \".0f\"\n",
        "    plt.figure(figsize=FIGSIZE_CM)\n",
        "    sns.heatmap(cm, annot=True, fmt=fmt, cmap=CMAP_PURPLE,\n",
        "                xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "    plt.title(title); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_roc_curves(y_true, y_proba, class_names, title_prefix=\"\"):\n",
        "    plt.figure(figsize=(7,6))\n",
        "    for i, cname in enumerate(class_names):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_proba[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{cname} (AUC = {roc_auc:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_true.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle='--', label=f\"Micro avg (AUC = {auc_micro:.3f})\")\n",
        "    plt.plot([0,1], [0,1], linestyle=':', color='gray')\n",
        "    plt.title(f\"{title_prefix} ROC Curves\")\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(loc=\"lower right\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "def subset_accuracy(y_true, y_pred_bin):\n",
        "    return np.mean(np.all(y_true == y_pred_bin, axis=1))\n",
        "\n",
        "def evaluate_split(split_name, X, y_true, model, threshold=THRESHOLD):\n",
        "    y_proba = model.predict(X)\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "    bin_acc = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "    sub_acc = subset_accuracy(y_true, y_pred)\n",
        "    per_class_acc = (y_true == y_pred).mean(axis=0)\n",
        "\n",
        "    print(f\"\\n=== {split_name} Metrics ===\")\n",
        "    print(f\"Binary Accuracy: {bin_acc:.4f}\")\n",
        "    print(f\"Subset Accuracy (exact match): {sub_acc:.4f}\")\n",
        "    for i, cname in enumerate(CLASS_NAMES):\n",
        "        print(f\"Accuracy for {cname}: {per_class_acc[i]:.4f}\")\n",
        "\n",
        "    for i, cname in enumerate(CLASS_NAMES):\n",
        "        print(f\"\\n-- {split_name} | {cname} --\")\n",
        "        print(classification_report(y_true[:, i], y_pred[:, i], target_names=[\"No\", \"Yes\"]))\n",
        "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
        "        plot_confusion(cm, title=f\"{split_name} Confusion Matrix - {cname} (Counts)\", normalize=False)\n",
        "        plot_confusion(cm, title=f\"{split_name} Confusion Matrix - {cname} (Normalized)\", normalize=True)\n",
        "\n",
        "    plot_roc_curves(y_true, y_proba, CLASS_NAMES, title_prefix=f\"{split_name}\")\n",
        "\n",
        "    label_map = {\n",
        "        (0,0): \"Normal\",\n",
        "        (1,0): \"Crackles only\",\n",
        "        (0,1): \"Wheezes only\",\n",
        "        (1,1): \"Crackles & Wheezes\"\n",
        "    }\n",
        "    def map_labels(Y): return [label_map.get(tuple(row), \"Other\") for row in Y]\n",
        "    y_true_combo = map_labels(y_true)\n",
        "    y_pred_combo = map_labels(y_pred)\n",
        "    labels_order = ['Normal', 'Crackles only', 'Wheezes only', 'Crackles & Wheezes']\n",
        "    cm4 = confusion_matrix(y_true_combo, y_pred_combo, labels=labels_order)\n",
        "    print(f\"\\n{split_name} — 4-Class Confusion Matrix:\")\n",
        "    plot_confusion(cm4, title=f\"{split_name} 4-Class Confusion\", normalize=False)\n",
        "\n",
        "plot_history(history)\n",
        "evaluate_split(\"Test\", X_test, y_test, model, threshold=THRESHOLD)"
      ],
      "metadata": {
        "id": "C-YSWt3T5zW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eeceb05"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, multilabel_confusion_matrix\n",
        "\n",
        "CLASS_NAMES = ['Crackles', 'Wheezes']\n",
        "CMAP_PURPLE = \"Purples\"\n",
        "FIGSIZE_CM = (5.5, 4.5)\n",
        "THRESHOLD = 0.5\n",
        "DO_THRESHOLD_SWEEP = True\n",
        "\n",
        "def get_var(name):\n",
        "    g = globals()\n",
        "    return g[name] if name in g else None\n",
        "\n",
        "def ensure_2d(y):\n",
        "    y = np.asarray(y)\n",
        "    if y.ndim == 1:\n",
        "        C = int(y.max()) + 1\n",
        "        Y = np.zeros((y.shape[0], C), dtype=int)\n",
        "        Y[np.arange(y.shape[0]), y] = 1\n",
        "        return Y\n",
        "    return y\n",
        "\n",
        "def plot_history_cnn_lstm(history):\n",
        "    if not history or not hasattr(history, \"history\"):\n",
        "        print(\"No training history found for CNN-LSTM.\")\n",
        "        return\n",
        "    hist = history.history\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(hist.get('loss', []), label='Train Loss')\n",
        "    plt.plot(hist.get('val_loss', []), label='Val Loss')\n",
        "    plt.title('CNN-LSTM Training & Validation Loss')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(hist.get('accuracy', []), label='Train Acc')\n",
        "    plt.plot(hist.get('val_accuracy', []), label='Val Acc')\n",
        "    plt.title('CNN-LSTM Training & Validation Accuracy')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_confusion_cnn_lstm(cm, title=\"Confusion Matrix\", normalize=False):\n",
        "    cm = np.asarray(cm, dtype=float)\n",
        "    if normalize:\n",
        "        with np.errstate(invalid='ignore'):\n",
        "            row_sum = cm.sum(axis=1, keepdims=True)\n",
        "            cm = np.divide(cm, row_sum, out=np.zeros_like(cm), where=row_sum != 0)\n",
        "        fmt = \".2f\"\n",
        "    else:\n",
        "        fmt = \".0f\"\n",
        "    plt.figure(figsize=FIGSIZE_CM)\n",
        "    sns.heatmap(cm, annot=True, fmt=fmt, cmap=CMAP_PURPLE,\n",
        "                xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "    plt.title(title); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_roc_curves_cnn_lstm(y_true, y_proba, class_names, title_prefix=\"\"):\n",
        "    plt.figure(figsize=(7,6))\n",
        "    for i, cname in enumerate(class_names):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_proba[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{cname} (AUC = {roc_auc:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_true.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle='--', label=f\"Micro avg (AUC = {auc_micro:.3f})\")\n",
        "    plt.plot([0,1], [0,1], linestyle=':', color='gray')\n",
        "    plt.title(f\"CNN-LSTM {title_prefix} ROC Curves\")\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(loc=\"lower right\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "def subset_accuracy(y_true, y_pred_bin):\n",
        "    return np.mean(np.all(y_true == y_pred_bin, axis=1))\n",
        "\n",
        "def evaluate_split_cnn_lstm(split_name, X, y_true, model, threshold=THRESHOLD):\n",
        "    y_proba = model.predict(X)\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "    bin_acc = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "    sub_acc = subset_accuracy(y_true, y_pred)\n",
        "    per_class_acc = (y_true == y_pred).mean(axis=0)\n",
        "\n",
        "    print(f\"\\n=== CNN-LSTM {split_name} Metrics ===\")\n",
        "    print(f\"Binary Accuracy: {bin_acc:.4f}\")\n",
        "    print(f\"Subset Accuracy (exact match): {sub_acc:.4f}\")\n",
        "    for i, cname in enumerate(CLASS_NAMES):\n",
        "        print(f\"Accuracy for {cname}: {per_class_acc[i]:.4f}\")\n",
        "\n",
        "    for i, cname in enumerate(CLASS_NAMES):\n",
        "        print(f\"\\n-- CNN-LSTM {split_name} | {cname} --\")\n",
        "        print(classification_report(y_true[:, i], y_pred[:, i], target_names=[\"No\", \"Yes\"]))\n",
        "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
        "        plot_confusion_cnn_lstm(cm, title=f\"CNN-LSTM {split_name} Confusion Matrix - {cname} (Counts)\", normalize=False)\n",
        "        plot_confusion_cnn_lstm(cm, title=f\"CNN-LSTM {split_name} Confusion Matrix - {cname} (Normalized)\", normalize=True)\n",
        "\n",
        "    plot_roc_curves_cnn_lstm(y_true, y_proba, CLASS_NAMES, title_prefix=f\"{split_name}\")\n",
        "\n",
        "    label_map = {\n",
        "        (0,0): \"Normal\",\n",
        "        (1,0): \"Crackles only\",\n",
        "        (0,1): \"Wheezes only\",\n",
        "        (1,1): \"Crackles & Wheezes\"\n",
        "    }\n",
        "    def map_labels(Y): return [label_map.get(tuple(row), \"Other\") for row in Y]\n",
        "    y_true_combo = map_labels(y_true)\n",
        "    y_pred_combo = map_labels(y_pred)\n",
        "    labels_order = ['Normal', 'Crackles only', 'Wheezes only', 'Crackles & Wheezes']\n",
        "    cm4 = confusion_matrix(y_true_combo, y_pred_combo, labels=labels_order)\n",
        "    print(f\"\\nCNN-LSTM {split_name} — 4-Class Confusion Matrix:\")\n",
        "    plot_confusion_cnn_lstm(cm4, title=f\"CNN-LSTM {split_name} 4-Class Confusion\", normalize=False)\n",
        "\n",
        "def threshold_sweep_cnn_lstm(split_name, X, y, model, class_names, thresholds=np.linspace(0.2, 0.8, 13)):\n",
        "    X = np.asarray(X); y = ensure_2d(y)\n",
        "    y_proba = model.predict(X)\n",
        "    best = {\"threshold\": None, \"subset_acc\": -1}\n",
        "    results = []\n",
        "    for t in thresholds:\n",
        "        y_pred_bin = (y_proba >= t).astype(int)\n",
        "        sa = subset_accuracy(y, y_pred_bin)\n",
        "        keras_bin_acc = accuracy_score(y.flatten(), y_pred_bin.flatten())\n",
        "        pla = (y == y_pred_bin).mean(axis=0)\n",
        "        results.append((t, sa, keras_bin_acc, *pla))\n",
        "        if sa > best[\"subset_acc\"]:\n",
        "            best = {\"threshold\": t, \"subset_acc\": sa}\n",
        "    results = np.array(results)\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(results[:,0], results[:,1], marker=\"o\", label=\"Subset Acc\")\n",
        "    plt.plot(results[:,0], results[:,2], marker=\"s\", label=\"Keras Binary Acc\")\n",
        "    for i, cname in enumerate(class_names):\n",
        "        plt.plot(results[:,0], results[:,3+i], marker=\".\", label=f\"Per-label Acc: {cname}\")\n",
        "    plt.title(f\"CNN-LSTM {split_name} Threshold Sweep\")\n",
        "    plt.xlabel(\"Threshold\"); plt.ylabel(\"Accuracy\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    print(f\"Best subset-accuracy threshold for CNN-LSTM {split_name}: {best['threshold']:.2f} (subset_acc={best['subset_acc']:.4f})\")\n",
        "    return results\n",
        "\n",
        "cnn_lstm_model = model\n",
        "cnn_lstm_history = history\n",
        "\n",
        "plot_history_cnn_lstm(cnn_lstm_history)\n",
        "\n",
        "SPLITS = {\n",
        "    \"Train\": (\"X_train\", \"y_train\"),\n",
        "    \"Val\":   (\"X_val\",   \"y_val\"),\n",
        "    \"Test\":  (\"X_test\",  \"y_test\"),\n",
        "}\n",
        "\n",
        "print(\"\\nEvaluating CNN-LSTM Model:\")\n",
        "for split_name, (Xn, Yn) in SPLITS.items():\n",
        "    Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "    if Xv is None or Yv is None:\n",
        "        print(f\"{split_name}: missing split; skipping.\")\n",
        "        continue\n",
        "    evaluate_split_cnn_lstm(split_name, Xv, Yv, cnn_lstm_model, threshold=THRESHOLD)\n",
        "\n",
        "if DO_THRESHOLD_SWEEP:\n",
        "    print(\"\\nRunning Threshold Sweeps for CNN-LSTM Model:\")\n",
        "    for split_name, (Xn, Yn) in SPLITS.items():\n",
        "        Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "        if Xv is None or Yv is None:\n",
        "            continue\n",
        "        threshold_sweep_cnn_lstm(split_name, Xv, Yv, cnn_lstm_model, CLASS_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "278728b7"
      },
      "source": [
        "### CNN-LSTM Model Summary of Findings\n",
        "\n",
        "Here is a summary of the CNN-LSTM model's performance on the training and test sets (using a threshold of 0.5):\n",
        "\n",
        "| Metric                     | Train Set (Overall) | Test Set (Overall) | Crackles (Train) | Wheezes (Train) | Crackles (Test) | Wheezes (Test) |\n",
        "|----------------------------|---------------------|--------------------|------------------|-----------------|-----------------|----------------|\n",
        "| Keras Binary Accuracy      | 0.7788              | 0.7309             | -                | -               | -               | -              |\n",
        "| Subset Accuracy            | 0.6129              | 0.5517             | -                | -               | -               | -              |\n",
        "| Loss (Final Epoch)         | 0.4402              | 0.5329             | -                | -               | -               | -              |\n",
        "| Precision                  | -                   | -                  | 0.705            | 0.648           | 0.504           | 0.415          |\n",
        "| Recall                     | -                   | -                  | 0.440            | 0.216           | 0.314           | 0.122          |\n",
        "| F1-Score                   | -                   | -                  | 0.542            | 0.324           | 0.389           | 0.191          |\n",
        "\n",
        "**Key Observations:**\n",
        "\n",
        "*   The CNN-LSTM model shows lower overall accuracy and higher loss on both the training and test sets compared to the standalone CNN model.\n",
        "*   There is a performance drop from the training to the test set, similar to the CNN, indicating some overfitting.\n",
        "*   Compared to the CNN, the CNN-LSTM shows lower precision, recall, and F1-scores for both 'Crackles' and 'Wheezes' on the test set (using the default 0.5 threshold).\n",
        "*   Specifically for 'Wheezes' on the test set, the recall (0.122) is similar to the MLP model's performance and lower than the CNN model's recall (0.387).\n",
        "*   The 4-class confusion matrix provides a detailed breakdown of classification performance across the combined categories.\n",
        "\n",
        "Based on these initial results with a 0.5 threshold, the CNN-LSTM model as implemented here does not appear to outperform the standalone CNN or even the simpler MLP model, particularly for the 'Wheezes' class. Further tuning of the CNN-LSTM architecture, hyperparameters, or exploration of different features might be needed to improve its performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPooling2D, Dropout, Reshape,\n",
        "    Bidirectional, LSTM, Dense\n",
        ")\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data_dir = '/content/ICBHI_extracted/ICBHI_final_database/processed_features'\n",
        "X = np.load(os.path.join(data_dir, 'mel_spectrograms.npy'))\n",
        "y = np.load(os.path.join(data_dir, 'labels.npy'))\n",
        "\n",
        "X = X[..., np.newaxis]\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, shuffle=True)\n",
        "\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        self.W = Dense(1, activation='tanh')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention = self.W(inputs)\n",
        "        attention = tf.nn.softmax(attention, axis=1)\n",
        "        context_vector = tf.reduce_sum(inputs * attention, axis=1)\n",
        "        return context_vector\n",
        "\n",
        "input_layer = Input(shape=(128, 157, 1))\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Reshape((x.shape[1], -1))(x)\n",
        "\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "x = AttentionLayer()(x)\n",
        "\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "output_layer = Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_path = os.path.join(data_dir, 'cnn_lstm_attention_model.h5')\n",
        "model.save(model_path)\n",
        "print(f\" Attention-based CNN-LSTM model saved to: {model_path}\")\n",
        "\n",
        "y_test_pred_probs = model.predict(X_test)\n",
        "y_test_pred = (y_test_pred_probs > 0.5).astype(int)\n",
        "\n",
        "print(\"\\n Classification Report - TEST\")\n",
        "print(classification_report(y_test, y_test_pred, target_names=['Crackles', 'Wheezes']))\n",
        "\n",
        "cm_test = multilabel_confusion_matrix(y_test, y_test_pred)\n",
        "labels_list = ['Crackles', 'Wheezes']\n",
        "\n",
        "for i, label in enumerate(labels_list):\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    sns.heatmap(cm_test[i], annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "    plt.title(f'Confusion Matrix - {label}')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Tc-9oYJ_654f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe19a5e4"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_curve, auc,\n",
        "    accuracy_score, multilabel_confusion_matrix\n",
        ")\n",
        "\n",
        "CLASS_NAMES = [\"Crackles\", \"Wheezes\"]\n",
        "CMAP_PURPLE = \"Purples\"\n",
        "FIGSIZE_CM = (5.5, 4.5)\n",
        "THRESHOLD = 0.5\n",
        "DO_THRESHOLD_SWEEP = True\n",
        "\n",
        "def get_var(name):\n",
        "    g = globals()\n",
        "    return g[name] if name in g else None\n",
        "\n",
        "def ensure_2d(y):\n",
        "    y = np.asarray(y)\n",
        "    if y.ndim == 1:\n",
        "        C = int(y.max()) + 1\n",
        "        Y = np.zeros((y.shape[0], C), dtype=int)\n",
        "        Y[np.arange(y.shape[0]), y] = 1\n",
        "        return Y\n",
        "    return y\n",
        "\n",
        "def plot_history_cnn_lstm_attention(history):\n",
        "    if not history or not hasattr(history, \"history\"):\n",
        "        print(\"No training history found for CNN-LSTM Attention.\")\n",
        "        return\n",
        "    hist = history.history\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(hist.get('loss', []), label='Train Loss')\n",
        "    plt.plot(hist.get('val_loss', []), label='Val Loss')\n",
        "    plt.title('CNN-LSTM Attention Training & Validation Loss')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(hist.get('accuracy', []), label='Train Acc')\n",
        "    plt.plot(hist.get('val_accuracy', []), label='Val Acc')\n",
        "    plt.title('CNN-LSTM Attention Training & Validation Accuracy')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_confusion_cnn_lstm_attention(cm, title=\"Confusion Matrix\", normalize=False):\n",
        "    cm = np.asarray(cm, dtype=float)\n",
        "    if normalize:\n",
        "        with np.errstate(invalid='ignore'):\n",
        "            row_sum = cm.sum(axis=1, keepdims=True)\n",
        "            cm = np.divide(cm, row_sum, out=np.zeros_like(cm), where=row_sum != 0)\n",
        "        fmt = \".2f\"\n",
        "    else:\n",
        "        fmt = \".0f\"\n",
        "    plt.figure(figsize=FIGSIZE_CM)\n",
        "    sns.heatmap(cm, annot=True, fmt=fmt, cmap=CMAP_PURPLE,\n",
        "                xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "    plt.title(title); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_roc_curves_cnn_lstm_attention(y_true, y_proba, class_names, title_prefix=\"\"):\n",
        "    plt.figure(figsize=(7,6))\n",
        "    for i, cname in enumerate(class_names):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_proba[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{cname} (AUC = {roc_auc:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_true.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle='--', label=f\"Micro avg (AUC = {auc_micro:.3f})\")\n",
        "    plt.plot([0,1], [0,1], linestyle=':', color='gray')\n",
        "    plt.title(f\"CNN-LSTM Attention {title_prefix} ROC Curves\")\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(loc=\"lower right\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "def subset_accuracy(y_true, y_pred_bin):\n",
        "    return np.mean(np.all(y_true == y_pred_bin, axis=1))\n",
        "\n",
        "def evaluate_split_cnn_lstm_attention(split_name, X, y_true, model, threshold=THRESHOLD):\n",
        "    y_proba = model.predict(X)\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "    bin_acc = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "    sub_acc = subset_accuracy(y_true, y_pred)\n",
        "    per_class_acc = (y_true == y_pred).mean(axis=0)\n",
        "\n",
        "    print(f\"\\n=== CNN-LSTM Attention {split_name} Metrics ===\")\n",
        "    print(f\"Binary Accuracy: {bin_acc:.4f}\")\n",
        "    print(f\"Subset Accuracy (exact match): {sub_acc:.4f}\")\n",
        "    for i, cname in enumerate(CLASS_NAMES):\n",
        "        print(f\"Accuracy for {cname}: {per_class_acc[i]:.4f}\")\n",
        "\n",
        "    for i, cname in enumerate(CLASS_NAMES):\n",
        "        print(f\"\\n-- CNN-LSTM Attention {split_name} | {cname} --\")\n",
        "        print(classification_report(y_true[:, i], y_pred[:, i], target_names=[\"No\", \"Yes\"]))\n",
        "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
        "        plot_confusion_cnn_lstm_attention(cm, title=f\"CNN-LSTM Attention {split_name} Confusion Matrix - {cname} (Counts)\", normalize=False)\n",
        "        plot_confusion_cnn_lstm_attention(cm, title=f\"CNN-LSTM Attention {split_name} Confusion Matrix - {cname} (Normalized)\", normalize=True)\n",
        "\n",
        "    plot_roc_curves_cnn_lstm_attention(y_true, y_proba, CLASS_NAMES, title_prefix=f\"{split_name}\")\n",
        "\n",
        "    label_map = {\n",
        "        (0,0): \"Normal\",\n",
        "        (1,0): \"Crackles only\",\n",
        "        (0,1): \"Wheezes only\",\n",
        "        (1,1): \"Crackles & Wheezes\"\n",
        "    }\n",
        "    def map_labels(Y): return [label_map.get(tuple(row), \"Other\") for row in Y]\n",
        "    y_true_combo = map_labels(y_true)\n",
        "    y_pred_combo = map_labels(y_pred)\n",
        "    labels_order = ['Normal', 'Crackles only', 'Wheezes only', 'Crackles & Wheezes']\n",
        "    cm4 = confusion_matrix(y_true_combo, y_pred_combo, labels=labels_order)\n",
        "    print(f\"\\nCNN-LSTM Attention {split_name} — 4-Class Confusion Matrix:\")\n",
        "    plot_confusion_cnn_lstm_attention(cm4, title=f\"CNN-LSTM Attention {split_name} 4-Class Confusion\", normalize=False)\n",
        "\n",
        "def threshold_sweep_cnn_lstm_attention(split_name, X, y, model, class_names, thresholds=np.linspace(0.2, 0.8, 13)):\n",
        "    X = np.asarray(X); y = ensure_2d(y)\n",
        "    y_proba = model.predict(X)\n",
        "    best = {\"threshold\": None, \"subset_acc\": -1}\n",
        "    results = []\n",
        "    for t in thresholds:\n",
        "        y_pred_bin = (y_proba >= t).astype(int)\n",
        "        sa = subset_accuracy(y, y_pred_bin)\n",
        "        keras_bin_acc = accuracy_score(y.flatten(), y_pred_bin.flatten())\n",
        "        pla = (y == y_pred_bin).mean(axis=0)\n",
        "        results.append((t, sa, keras_bin_acc, *pla))\n",
        "        if sa > best[\"subset_acc\"]:\n",
        "            best = {\"threshold\": t, \"subset_acc\": sa}\n",
        "    results = np.array(results)\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(results[:,0], results[:,1], marker=\"o\", label=\"Subset Acc\")\n",
        "    plt.plot(results[:,0], results[:,2], marker=\"s\", label=\"Keras Binary Acc\")\n",
        "    for i, cname in enumerate(class_names):\n",
        "        plt.plot(results[:,0], results[:,3+i], marker=\".\", label=f\"Per-label Acc: {cname}\")\n",
        "    plt.title(f\"CNN-LSTM Attention {split_name} Threshold Sweep\")\n",
        "    plt.xlabel(\"Threshold\"); plt.ylabel(\"Accuracy\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    print(f\"Best subset-accuracy threshold for CNN-LSTM Attention {split_name}: {best['threshold']:.2f} (subset_acc={best['subset_acc']:.4f})\")\n",
        "    return results\n",
        "\n",
        "cnn_lstm_attention_model = model\n",
        "cnn_lstm_attention_history = history\n",
        "\n",
        "plot_history_cnn_lstm_attention(cnn_lstm_attention_history)\n",
        "\n",
        "SPLITS = {\n",
        "    \"Train\": (\"X_train\", \"y_train\"),\n",
        "    \"Val\":   (\"X_val\",   \"y_val\"),\n",
        "    \"Test\":  (\"X_test\",  \"y_test\"),\n",
        "}\n",
        "\n",
        "print(\"\\nEvaluating CNN-LSTM Attention Model:\")\n",
        "for split_name, (Xn, Yn) in SPLITS.items():\n",
        "    Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "    if Xv is None or Yv is None:\n",
        "        print(f\"{split_name}: missing split; skipping.\")\n",
        "        continue\n",
        "    evaluate_split_cnn_lstm_attention(split_name, Xv, Yv, cnn_lstm_attention_model, threshold=THRESHOLD)\n",
        "\n",
        "if DO_THRESHOLD_SWEEP:\n",
        "    print(\"\\nRunning Threshold Sweeps for CNN-LSTM Attention Model:\")\n",
        "    for split_name, (Xn, Yn) in SPLITS.items():\n",
        "        Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "        if Xv is None or Yv is None:\n",
        "            continue\n",
        "        threshold_sweep_cnn_lstm_attention(split_name, Xv, Yv, cnn_lstm_attention_model, CLASS_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f4bf6d1"
      },
      "source": [
        "### CNN-LSTM Attention Model Summary of Findings\n",
        "\n",
        "Here is a summary of the CNN-LSTM Attention model's performance on the training and test sets (using a threshold of 0.5):\n",
        "\n",
        "| Metric                     | Train Set (Overall) | Test Set (Overall) | Crackles (Train) | Wheezes (Train) | Crackles (Test) | Wheezes (Test) |\n",
        "|----------------------------|---------------------|--------------------|------------------|-----------------|-----------------|----------------|\n",
        "| Keras Binary Accuracy      | 0.7854              | 0.7314             | -                | -               | -               | -              |\n",
        "| Subset Accuracy            | 0.6162              | 0.5507             | -                | -               | -               | -              |\n",
        "| Loss (Final Epoch)         | 0.3542              | 0.6142             | -                | -               | -               | -              |\n",
        "| Precision                  | -                   | -                  | 0.644            | 0.726           | 0.492           | 0.470          |\n",
        "| Recall                     | -                   | -                  | 0.573            | 0.272           | 0.452           | 0.149          |\n",
        "| F1-Score                   | -                   | -                  | 0.606            | 0.397           | 0.471           | 0.227          |\n",
        "\n",
        "**Key Observations:**\n",
        "\n",
        "*   The CNN-LSTM Attention model shows training performance metrics that are generally similar to or slightly better than the basic CNN-LSTM model, but not as strong as the standalone CNN on the training set.\n",
        "*   There is a noticeable drop in performance from the training to the test set, indicating overfitting, similar to the other models.\n",
        "*   On the test set (using the default 0.5 threshold), the CNN-LSTM Attention model's performance is comparable to the basic CNN-LSTM and generally lower than the standalone CNN, particularly in terms of overall accuracy and F1-scores for both classes.\n",
        "*   The recall for 'Wheezes' on the test set (0.149) is still low and comparable to the MLP and basic CNN-LSTM models, suggesting that the attention mechanism in this configuration did not significantly improve the detection of this minority class.\n",
        "*   The 4-class confusion matrix provides a detailed breakdown of classification performance across the combined categories.\n",
        "\n",
        "Based on these initial results with a 0.5 threshold, the CNN-LSTM Attention model as implemented here does not appear to offer a significant performance improvement over the simpler models for this task, especially for the 'Wheezes' class. Further experimentation with the model architecture, hyperparameters, or attention mechanism might be necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4183f078"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "y_train_flat = y_train.flatten()\n",
        "\n",
        "classes = np.array([0, 1])\n",
        "\n",
        "weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=y_train_flat\n",
        ")\n",
        "\n",
        "class_weights_dict = {i: weights[i] for i in range(len(classes))}\n",
        "\n",
        "print(\"Calculated Class Weights:\", class_weights_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27730c51"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPooling2D, Dropout, Reshape,\n",
        "    Bidirectional, LSTM, Dense\n",
        ")\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "input_layer = Input(shape=(128, 157, 1))\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Reshape((32, 39 * 64))(x)\n",
        "\n",
        "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        self.W = Dense(1, activation='tanh')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention = self.W(inputs)\n",
        "        attention = tf.nn.softmax(attention, axis=1)\n",
        "        context_vector = tf.reduce_sum(inputs * attention, axis=1)\n",
        "        return context_vector\n",
        "\n",
        "x = AttentionLayer()(x)\n",
        "\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "output_layer = Dense(2, activation='sigmoid')(x)\n",
        "\n",
        "cnn_lstm_attention_weighted_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "cnn_lstm_attention_weighted_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "cnn_lstm_attention_weighted_model.summary()\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "cnn_lstm_attention_weighted_history = cnn_lstm_attention_weighted_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    class_weight=class_weights_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "save_dir = '/content/ICBHI_extracted/ICBHI_final_database/processed_features'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "model_path = os.path.join(save_dir, 'cnn_lstm_attention_weighted_model.h5')\n",
        "cnn_lstm_attention_weighted_model.save(model_path)\n",
        "print(f\" Attention-based CNN-LSTM (Weighted) model saved to: {model_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca3eff89"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_curve, auc,\n",
        "    accuracy_score, multilabel_confusion_matrix\n",
        ")\n",
        "\n",
        "CLASS_NAMES = [\"Crackles\", \"Wheezes\"]\n",
        "CMAP_PURPLE = \"Purples\"\n",
        "FIGSIZE_CM = (5.5, 4.5)\n",
        "THRESHOLD = 0.5\n",
        "DO_THRESHOLD_SWEEP = True\n",
        "\n",
        "def get_var(name):\n",
        "    g = globals()\n",
        "    return g[name] if name in g else None\n",
        "\n",
        "def ensure_2d(y):\n",
        "    y = np.asarray(y)\n",
        "    if y.ndim == 1:\n",
        "        C = int(y.max()) + 1\n",
        "        Y = np.zeros((y.shape[0], C), dtype=int)\n",
        "        Y[np.arange(y.shape[0]), y] = 1\n",
        "        return Y\n",
        "    return y\n",
        "\n",
        "def plot_history_weighted_cnn_lstm_attention(history):\n",
        "    if not history or not hasattr(history, \"history\"):\n",
        "        print(\"No training history found for Weighted CNN-LSTM Attention.\")\n",
        "        return\n",
        "    hist = history.history\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(hist.get('loss', []), label='Train Loss')\n",
        "    plt.plot(hist.get('val_loss', []), label='Val Loss')\n",
        "    plt.title('Weighted CNN-LSTM Attention Training & Validation Loss')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(hist.get('accuracy', []), label='Train Acc')\n",
        "    plt.plot(hist.get('val_accuracy', []), label='Val Acc')\n",
        "    plt.title('Weighted CNN-LSTM Attention Training & Validation Accuracy')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_confusion_weighted_cnn_lstm_attention(cm, title=\"Confusion Matrix\", normalize=False):\n",
        "    cm = np.asarray(cm, dtype=float)\n",
        "    if normalize:\n",
        "        with np.errstate(invalid='ignore'):\n",
        "            row_sum = cm.sum(axis=1, keepdims=True)\n",
        "            cm = np.divide(cm, row_sum, out=np.zeros_like(cm), where=row_sum != 0)\n",
        "        fmt = \".2f\"\n",
        "    else:\n",
        "        fmt = \".0f\"\n",
        "    plt.figure(figsize=FIGSIZE_CM)\n",
        "    sns.heatmap(cm, annot=True, fmt=fmt, cmap=CMAP_PURPLE,\n",
        "                xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "    plt.title(title); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_roc_curves_weighted_cnn_lstm_attention(y_true, y_proba, class_names, title_prefix=\"\"):\n",
        "    plt.figure(figsize=(7,6))\n",
        "    for i, cname in enumerate(class_names):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_proba[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{cname} (AUC = {roc_auc:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_true.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle='--', label=f\"Micro avg (AUC = {auc_micro:.3f})\")\n",
        "    plt.plot([0,1], [0,1], linestyle=':', color='gray')\n",
        "    plt.title(f\"Weighted CNN-LSTM Attention {title_prefix} ROC Curves\")\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(loc=\"lower right\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "def subset_accuracy(y_true, y_pred_bin):\n",
        "    return np.mean(np.all(y_true == y_pred_bin, axis=1))\n",
        "\n",
        "def evaluate_split_weighted_cnn_lstm_attention(split_name, X, y_true, model, threshold=THRESHOLD):\n",
        "    y_proba = model.predict(X)\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "    bin_acc = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "    sub_acc = subset_accuracy(y_true, y_pred)\n",
        "    per_class_acc = (y_true == y_pred).mean(axis=0)\n",
        "\n",
        "    print(f\"\\n=== Weighted CNN-LSTM Attention {split_name} Metrics ===\")\n",
        "    print(f\"Binary Accuracy: {bin_acc:.4f}\")\n",
        "    print(f\"Subset Accuracy (exact match): {sub_acc:.4f}\")\n",
        "    for i, cname in enumerate(CLASS_NAMES):\n",
        "        print(f\"Accuracy for {cname}: {per_class_acc[i]:.4f}\")\n",
        "\n",
        "    for i, cname in enumerate(CLASS_NAMES):\n",
        "        print(f\"\\n-- Weighted CNN-LSTM Attention {split_name} | {cname} --\")\n",
        "        print(classification_report(y_true[:, i], y_pred[:, i], target_names=[\"No\", \"Yes\"]))\n",
        "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
        "        plot_confusion_weighted_cnn_lstm_attention(cm, title=f\"Weighted CNN-LSTM Attention {split_name} Confusion Matrix - {cname} (Counts)\", normalize=False)\n",
        "        plot_confusion_weighted_cnn_lstm_attention(cm, title=f\"Weighted CNN-LSTM Attention {split_name} Confusion Matrix - {cname} (Normalized)\", normalize=True)\n",
        "\n",
        "    plot_roc_curves_weighted_cnn_lstm_attention(y_true, y_proba, CLASS_NAMES, title_prefix=f\"{split_name}\")\n",
        "\n",
        "    label_map = {\n",
        "        (0,0): \"Normal\",\n",
        "        (1,0): \"Crackles only\",\n",
        "        (0,1): \"Wheezes only\",\n",
        "        (1,1): \"Crackles & Wheezes\"\n",
        "    }\n",
        "    def map_labels(Y): return [label_map.get(tuple(row), \"Other\") for row in Y]\n",
        "    y_true_combo = map_labels(y_true)\n",
        "    y_pred_combo = map_labels(y_pred)\n",
        "    labels_order = ['Normal', 'Crackles only', 'Wheezes only', 'Crackles & Wheezes']\n",
        "    cm4 = confusion_matrix(y_true_combo, y_pred_combo, labels=labels_order)\n",
        "    print(f\"\\nWeighted CNN-LSTM Attention {split_name} — 4-Class Confusion Matrix:\")\n",
        "    plot_confusion_weighted_cnn_lstm_attention(cm4, title=f\"Weighted CNN-LSTM Attention {split_name} 4-Class Confusion\", normalize=False)\n",
        "\n",
        "def threshold_sweep_weighted_cnn_lstm_attention(split_name, X, y, model, class_names, thresholds=np.linspace(0.2, 0.8, 13)):\n",
        "    X = np.asarray(X); y = ensure_2d(y)\n",
        "    y_proba = model.predict(X)\n",
        "    best = {\"threshold\": None, \"subset_acc\": -1}\n",
        "    results = []\n",
        "    for t in thresholds:\n",
        "        y_pred_bin = (y_proba >= t).astype(int)\n",
        "        sa = subset_accuracy(y, y_pred_bin)\n",
        "        keras_bin_acc = accuracy_score(y.flatten(), y_pred_bin.flatten())\n",
        "        pla = (y == y_pred_bin).mean(axis=0)\n",
        "        results.append((t, sa, keras_bin_acc, *pla))\n",
        "        if sa > best[\"subset_acc\"]:\n",
        "            best = {\"threshold\": t, \"subset_acc\": sa}\n",
        "    results = np.array(results)\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(results[:,0], results[:,1], marker=\"o\", label=\"Subset Acc\")\n",
        "    plt.plot(results[:,0], results[:,2], marker=\"s\", label=\"Keras Binary Acc\")\n",
        "    for i, cname in enumerate(class_names):\n",
        "        plt.plot(results[:,0], results[:,3+i], marker=\".\", label=f\"Per-label Acc: {cname}\")\n",
        "    plt.title(f\"Weighted CNN-LSTM Attention {split_name} Threshold Sweep\")\n",
        "    plt.xlabel(\"Threshold\"); plt.ylabel(\"Accuracy\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    print(f\"Best subset-accuracy threshold for Weighted CNN-LSTM Attention {split_name}: {best['threshold']:.2f} (subset_acc={best['subset_acc']:.4f})\")\n",
        "    return results\n",
        "\n",
        "weighted_model = cnn_lstm_attention_weighted_model\n",
        "weighted_history = cnn_lstm_attention_weighted_history\n",
        "\n",
        "plot_history_weighted_cnn_lstm_attention(weighted_history)\n",
        "\n",
        "SPLITS = {\n",
        "    \"Train\": (\"X_train\", \"y_train\"),\n",
        "    \"Val\":   (\"X_val\",   \"y_val\"),\n",
        "    \"Test\":  (\"X_test\",  \"y_test\"),\n",
        "}\n",
        "\n",
        "print(\"\\nEvaluating Weighted CNN-LSTM Attention Model:\")\n",
        "for split_name, (Xn, Yn) in SPLITS.items():\n",
        "    Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "    if Xv is None or Yv is None:\n",
        "        print(f\"{split_name}: missing split; skipping.\")\n",
        "        continue\n",
        "    evaluate_split_weighted_cnn_lstm_attention(split_name, Xv, Yv, weighted_model, threshold=THRESHOLD)\n",
        "\n",
        "if DO_THRESHOLD_SWEEP:\n",
        "    print(\"\\nRunning Threshold Sweeps for Weighted CNN-LSTM Attention Model:\")\n",
        "    for split_name, (Xn, Yn) in SPLITS.items():\n",
        "        Xv = get_var(Xn); Yv = get_var(Yn)\n",
        "        if Xv is None or Yv is None:\n",
        "            continue\n",
        "        threshold_sweep_weighted_cnn_lstm_attention(split_name, Xv, Yv, weighted_model, CLASS_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b5b873e"
      },
      "source": [
        "### Weighted CNN-LSTM Attention Model Summary of Findings\n",
        "\n",
        "Here is a summary of the Weighted CNN-LSTM Attention model's performance on the training and test sets (using a threshold of 0.5):\n",
        "\n",
        "| Metric                     | Train Set (Overall) | Test Set (Overall) | Crackles (Train) | Wheezes (Train) | Crackles (Test) | Wheezes (Test) |\n",
        "|----------------------------|---------------------|--------------------|------------------|-----------------|-----------------|----------------|\n",
        "| Keras Binary Accuracy      | 0.7720              | 0.7285             | -                | -               | -               | -              |\n",
        "| Subset Accuracy            | 0.5973              | 0.5217             | -                | -               | -               | -              |\n",
        "| Loss (Final Epoch)         | 0.3210              | 0.5749             | -                | -               | -               | -              |\n",
        "| Precision                  | -                   | -                  | 0.746            | 0.594           | 0.583           | 0.410          |\n",
        "| Recall                     | -                   | -                  | 0.273            | 0.506           | 0.185           | 0.338          |\n",
        "| F1-Score                   | -                   | -                  | 0.399            | 0.547           | 0.281           | 0.371          |\n",
        "\n",
        "**Key Observations:**\n",
        "\n",
        "*   Compared to the unweighted CNN-LSTM Attention model, applying class weights appears to have shifted the model's focus, leading to **lower training accuracy and higher training loss**, but potentially aiming for better performance on the minority class.\n",
        "*   On the test set (using the default 0.5 threshold):\n",
        "    *   **Crackles:** Precision increased significantly (from 0.492 to 0.583), but recall dropped substantially (from 0.452 to 0.185). This means the weighted model is more confident when predicting Crackles but misses many actual Crackles.\n",
        "    *   **Wheezes:** Precision slightly decreased (from 0.470 to 0.410), but recall saw a notable increase (from 0.149 to 0.338). This indicates the weighted model is better at finding actual Wheezes, though with more false positives.\n",
        "*   The subset accuracy on the test set is lower for the weighted model (0.5217) compared to the unweighted version (0.5507) at the 0.5 threshold.\n",
        "*   The threshold sweep results show that while the default 0.5 threshold might not be optimal, adjusting the threshold can improve subset accuracy, but the overall trade-offs between precision and recall for the classes are still evident.\n",
        "\n",
        "Handling class weights in this way has indeed improved the **recall for the 'Wheezes' class** on the test set, which was a major weakness in the previous models. However, this came at the cost of recall for the 'Crackles' class and overall subset accuracy at the default threshold. Further tuning of the class weights or exploring other imbalance handling techniques could potentially yield better overall balanced performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35147bfe"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "learning_rates = [0.001, 0.0005, 0.0001]\n",
        "\n",
        "lstm_units = [32, 64, 128]\n",
        "\n",
        "dropout_rates = [0.2, 0.3, 0.4, 0.5]\n",
        "\n",
        "dense_units = [32, 64, 128]\n",
        "\n",
        "batch_sizes = [16, 32, 64]\n",
        "\n",
        "print(\"Defined Hyperparameter Search Space:\")\n",
        "print(f\"  Learning Rates: {learning_rates}\")\n",
        "print(f\"  LSTM Units: {lstm_units}\")\n",
        "print(f\"  Dropout Rates: {dropout_rates}\")\n",
        "print(f\"  Dense Units: {dense_units}\")\n",
        "print(f\"  Batch Sizes: {batch_sizes}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2850e929"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPooling2D, Dropout, Reshape,\n",
        "    Bidirectional, LSTM, Dense\n",
        ")\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report, multilabel_confusion_matrix, accuracy_score\n",
        "\n",
        "NUM_TUNING_TRIALS = 20\n",
        "EARLY_STOPPING_PATIENCE = 5\n",
        "USE_CLASS_WEIGHTS = True\n",
        "\n",
        "tuning_results = []\n",
        "best_val_metric = -1\n",
        "best_hyperparameters = None\n",
        "\n",
        "print(f\"Starting Hyperparameter Tuning for {NUM_TUNING_TRIALS} trials...\")\n",
        "\n",
        "for trial in range(NUM_TUNING_TRIALS):\n",
        "    print(f\"\\n--- Trial {trial + 1}/{NUM_TUNING_TRIALS} ---\")\n",
        "\n",
        "    current_lr = random.choice(learning_rates)\n",
        "    current_lstm_units = random.choice(lstm_units)\n",
        "    current_dropout_rate_lstm = random.choice(dropout_rates)\n",
        "    current_dropout_rate_dense = random.choice(dropout_rates)\n",
        "    current_dense_units = random.choice(dense_units)\n",
        "    current_batch_size = random.choice(batch_sizes)\n",
        "\n",
        "    print(f\"  Hyperparameters: LR={current_lr}, LSTM Units={current_lstm_units}, Dropout(LSTM)={current_dropout_rate_lstm}, Dropout(Dense)={current_dropout_rate_dense}, Dense Units={current_dense_units}, Batch Size={current_batch_size}\")\n",
        "\n",
        "    class AttentionLayer(tf.keras.layers.Layer):\n",
        "        def __init__(self, **kwargs):\n",
        "            super(AttentionLayer, self).__init__(**kwargs)\n",
        "            self.W = Dense(1, activation='tanh')\n",
        "\n",
        "        def call(self, inputs):\n",
        "            attention = self.W(inputs)\n",
        "            attention = tf.nn.softmax(attention, axis=1)\n",
        "            context_vector = tf.reduce_sum(inputs * attention, axis=1)\n",
        "            return context_vector\n",
        "\n",
        "    model = Sequential([\n",
        "        Input(shape=(128, 157, 1)),\n",
        "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Reshape((32, 39 * 64)),\n",
        "\n",
        "        Bidirectional(LSTM(current_lstm_units, return_sequences=True)),\n",
        "        AttentionLayer(),\n",
        "\n",
        "        Dense(current_dense_units, activation='relu'),\n",
        "        Dropout(current_dropout_rate_dense),\n",
        "\n",
        "        Dense(2, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=current_lr)\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    early_stop_callback = EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True)\n",
        "\n",
        "    current_class_weight = class_weights_dict if USE_CLASS_WEIGHTS else None\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=current_batch_size,\n",
        "        callbacks=[early_stop_callback],\n",
        "        class_weight=current_class_weight,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "    y_val_pred_probs = model.predict(X_val, verbose=0)\n",
        "    y_val_pred = (y_val_pred_probs > 0.5).astype(int)\n",
        "\n",
        "    try:\n",
        "        report = classification_report(y_val, y_val_pred, target_names=['Crackles', 'Wheezes'], output_dict=True, zero_division=0)\n",
        "        wheezes_f1 = report['Wheezes']['f1-score']\n",
        "        crackles_f1 = report['Crackles']['f1-score']\n",
        "        micro_f1 = report['micro avg']['f1-score']\n",
        "    except Exception as e:\n",
        "        print(f\"  Error calculating classification report: {e}\")\n",
        "        wheezes_f1 = 0\n",
        "        crackles_f1 = 0\n",
        "        micro_f1 = 0\n",
        "\n",
        "\n",
        "    print(f\"  Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Wheezes F1: {wheezes_f1:.4f}, Crackles F1: {crackles_f1:.4f}, Micro F1: {micro_f1:.4f}\")\n",
        "\n",
        "    tuning_results.append({\n",
        "        'trial': trial + 1,\n",
        "        'learning_rate': current_lr,\n",
        "        'lstm_units': current_lstm_units,\n",
        "        'dropout_lstm': current_dropout_rate_lstm,\n",
        "        'dropout_dense': current_dropout_rate_dense,\n",
        "        'dense_units': current_dense_units,\n",
        "        'batch_size': current_batch_size,\n",
        "        'val_loss': val_loss,\n",
        "        'val_accuracy': val_accuracy,\n",
        "        'wheezes_f1': wheezes_f1,\n",
        "        'crackles_f1': crackles_f1,\n",
        "        'micro_f1': micro_f1,\n",
        "        'epochs_trained': len(history.history['loss'])\n",
        "    })\n",
        "\n",
        "    if micro_f1 > best_val_metric:\n",
        "        best_val_metric = micro_f1\n",
        "        best_hyperparameters = {\n",
        "            'learning_rate': current_lr,\n",
        "            'lstm_units': current_lstm_units,\n",
        "            'dropout_lstm': current_dropout_rate_lstm,\n",
        "            'dropout_dense': current_dropout_rate_dense,\n",
        "            'dense_units': current_dense_units,\n",
        "            'batch_size': current_batch_size,\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"\\nHyperparameter Tuning Finished.\")\n",
        "print(\"\\nBest Hyperparameters found (based on Validation Micro F1):\")\n",
        "print(best_hyperparameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "389ec0b6"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPooling2D, Dropout, Reshape,\n",
        "    Bidirectional, LSTM, Dense\n",
        ")\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_curve, auc,\n",
        "    accuracy_score, multilabel_confusion_matrix\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        self.W = Dense(1, activation='tanh')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention = self.W(inputs)\n",
        "        attention = tf.nn.softmax(attention, axis=1)\n",
        "        context_vector = tf.reduce_sum(inputs * attention, axis=1)\n",
        "        return context_vector\n",
        "\n",
        "X_train_combined = np.concatenate((X_train, X_val), axis=0)\n",
        "y_train_combined = np.concatenate((y_train, y_val), axis=0)\n",
        "\n",
        "print(f\"Combined training data shape: {X_train_combined.shape}\")\n",
        "print(f\"Combined training labels shape: {y_train_combined.shape}\")\n",
        "\n",
        "best_lr = best_hyperparameters['learning_rate']\n",
        "best_lstm_units = best_hyperparameters['lstm_units']\n",
        "best_dropout_dense = best_hyperparameters['dropout_dense']\n",
        "best_dense_units = best_hyperparameters['dense_units']\n",
        "best_batch_size = best_hyperparameters['batch_size']\n",
        "\n",
        "final_model = Sequential([\n",
        "    Input(shape=(128, 157, 1)),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Reshape((32, 39 * 64)),\n",
        "\n",
        "    Bidirectional(LSTM(best_lstm_units, return_sequences=True)),\n",
        "    AttentionLayer(),\n",
        "\n",
        "    Dense(best_dense_units, activation='relu'),\n",
        "    Dropout(best_dropout_dense),\n",
        "\n",
        "    Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=best_lr)\n",
        "final_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "final_model.summary()\n",
        "\n",
        "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
        "    X_train_combined, y_train_combined, test_size=0.1, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "early_stop_final = EarlyStopping(monitor='val_loss', patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True)\n",
        "\n",
        "current_class_weight = class_weights_dict if USE_CLASS_WEIGHTS else None\n",
        "\n",
        "print(\"\\nTraining final model with best hyperparameters...\")\n",
        "final_history = final_model.fit(\n",
        "    X_train_final, y_train_final,\n",
        "    validation_data=(X_val_final, y_val_final),\n",
        "    epochs=100,\n",
        "    batch_size=best_batch_size,\n",
        "    callbacks=[early_stop_final],\n",
        "    class_weight=current_class_weight,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "save_dir = '/content/ICBHI_extracted/ICBHI_final_database/processed_features'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "final_model_path = os.path.join(save_dir, 'cnn_lstm_attention_tuned_weighted_model.h5')\n",
        "final_model.save(final_model_path)\n",
        "print(f\" Final Tuned CNN-LSTM Attention Model saved to: {final_model_path}\")\n",
        "\n",
        "print(\"\\nEvaluating final model on Test Set...\")\n",
        "\n",
        "def plot_history_cnn_lstm_attention(history):\n",
        "    if not history or not hasattr(history, \"history\"):\n",
        "        print(\"No training history found for CNN-LSTM Attention.\")\n",
        "        return\n",
        "    hist = history.history\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(hist.get('loss', []), label='Train Loss')\n",
        "    plt.plot(hist.get('val_loss', []), label='Val Loss')\n",
        "    plt.title('CNN-LSTM Attention Training & Validation Loss')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(7, 4))\n",
        "    plt.plot(hist.get('accuracy', []), label='Train Acc')\n",
        "    plt.plot(hist.get('val_accuracy', []), label='Val Acc')\n",
        "    plt.title('CNN-LSTM Attention Training & Validation Accuracy')\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "def ensure_2d(y):\n",
        "    y = np.asarray(y)\n",
        "    if y.ndim == 1:\n",
        "        C = int(y.max()) + 1\n",
        "        Y = np.zeros((y.shape[0], C), dtype=int)\n",
        "        Y[np.arange(y.shape[0]), y] = 1\n",
        "        return Y\n",
        "    return y\n",
        "\n",
        "def predict_proba_cnn(model, X):\n",
        "    proba = model.predict(X, verbose=0)\n",
        "    proba = np.asarray(proba)\n",
        "    if proba.ndim == 1:\n",
        "        proba = proba[:, None]\n",
        "    return proba\n",
        "\n",
        "\n",
        "def plot_confusion_cnn_lstm_attention(cm, title=\"Confusion Matrix\", normalize=False):\n",
        "    cm = np.asarray(cm, dtype=float)\n",
        "    if normalize:\n",
        "        with np.errstate(invalid='ignore'):\n",
        "            row_sum = cm.sum(axis=1, keepdims=True)\n",
        "            cm = np.divide(cm, row_sum, out=np.zeros_like(cm), where=row_sum != 0)\n",
        "        fmt = \".2f\"\n",
        "    else:\n",
        "        fmt = \".0f\"\n",
        "    plt.figure(figsize=FIGSIZE_CM)\n",
        "    sns.heatmap(cm, annot=True, fmt=fmt, cmap=CMAP_PURPLE,\n",
        "                xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
        "    plt.title(title); plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "def plot_roc_curves_cnn_lstm_attention(y_true, y_proba, class_names, title_prefix=\"\"):\n",
        "    plt.figure(figsize=(7,6))\n",
        "    for i, cname in enumerate(class_names):\n",
        "        fpr, tpr, _ = roc_curve(y_true[:, i], y_proba[:, i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{cname} (AUC = {roc_auc:.3f})\")\n",
        "    fpr_micro, tpr_micro, _ = roc_curve(y_true.ravel(), y_proba.ravel())\n",
        "    auc_micro = auc(fpr_micro, tpr_micro)\n",
        "    plt.plot(fpr_micro, tpr_micro, linestyle='--', label=f\"Micro avg (AUC = {auc_micro:.3f})\")\n",
        "    plt.plot([0,1], [0,1], linestyle=':', color='gray')\n",
        "    plt.title(f\"CNN-LSTM Attention {title_prefix} ROC Curves\")\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "    plt.grid(True, alpha=0.3); plt.legend(loc=\"lower right\"); plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "def subset_accuracy(y_true, y_pred_bin):\n",
        "    return np.mean(np.all(y_true == y_pred_bin, axis=1))\n",
        "\n",
        "\n",
        "def evaluate_split_cnn_lstm_attention(split_name, X, y_true, model, threshold=THRESHOLD):\n",
        "    y_proba = model.predict(X)\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "\n",
        "    bin_acc = accuracy_score(y_true.flatten(), y_pred.flatten())\n",
        "    sub_acc = subset_accuracy(y_true, y_pred)\n",
        "    per_class_acc = (y_true == y_pred).mean(axis=0)\n",
        "\n",
        "    print(f\"\\n=== CNN-LSTM Attention {split_name} Metrics ===\")\n",
        "    print(f\"Binary Accuracy: {bin_acc:.4f}\")\n",
        "    print(f\"Subset Accuracy (exact match): {sub_acc:.4f}\")\n",
        "    for i, cname in enumerate(CLASS_NAMES):\n",
        "        print(f\"Accuracy for {cname}: {per_class_acc[i]:.4f}\")\n",
        "\n",
        "    for i, cname in enumerate(CLASS_NAMES):\n",
        "        print(f\"\\n-- CNN-LSTM Attention {split_name} | {cname} --\")\n",
        "        print(classification_report(y_true[:, i], y_pred[:, i], target_names=[\"No\", \"Yes\"]))\n",
        "        cm = confusion_matrix(y_true[:, i], y_pred[:, i])\n",
        "        plot_confusion_cnn_lstm_attention(cm, title=f\"CNN-LSTM Attention {split_name} Confusion Matrix - {cname} (Counts)\", normalize=False)\n",
        "        plot_confusion_cnn_lstm_attention(cm, title=f\"CNN-LSTM Attention {split_name} Confusion Matrix - {cname} (Normalized)\", normalize=True)\n",
        "\n",
        "    plot_roc_curves_cnn_lstm_attention(y_true, y_proba, CLASS_NAMES, title_prefix=f\"{split_name}\")\n",
        "\n",
        "    label_map = {\n",
        "        (0,0): \"Normal\",\n",
        "        (1,0): \"Crackles only\",\n",
        "        (0,1): \"Wheezes only\",\n",
        "        (1,1): \"Crackles & Wheezes\"\n",
        "    }\n",
        "    def map_labels(Y): return [label_map.get(tuple(row), \"Other\") for row in Y]\n",
        "    y_true_combo = map_labels(y_true)\n",
        "    y_pred_combo = map_labels(y_pred)\n",
        "    labels_order = ['Normal', 'Crackles only', 'Wheezes only', 'Crackles & Wheezes']\n",
        "    cm4 = confusion_matrix(y_true_combo, y_pred_combo, labels=labels_order)\n",
        "    print(f\"\\nCNN-LSTM Attention {split_name} — 4-Class Confusion Matrix:\")\n",
        "    plot_confusion_cnn_lstm_attention(cm4, title=f\"CNN-LSTM Attention {split_name} 4-Class Confusion\", normalize=False)\n",
        "\n",
        "\n",
        "def threshold_sweep_cnn_lstm_attention(split_name, X, y, model, class_names, thresholds=np.linspace(0.2, 0.8, 13)):\n",
        "    X = np.asarray(X); y = ensure_2d(y)\n",
        "    y_proba = model.predict(X)\n",
        "    best = {\"threshold\": None, \"subset_acc\": -1}\n",
        "    results = []\n",
        "    for t in thresholds:\n",
        "        y_pred_bin = (y_proba >= t).astype(int)\n",
        "        sa = subset_accuracy(y, y_pred_bin)\n",
        "        keras_bin_acc = accuracy_score(y.flatten(), y_pred_bin.flatten())\n",
        "        pla = (y == y_pred_bin).mean(axis=0)\n",
        "        results.append((t, sa, keras_bin_acc, *pla))\n",
        "        if sa > best[\"subset_acc\"]:\n",
        "            best = {\"threshold\": t, \"subset_acc\": sa}\n",
        "    results = np.array(results)\n",
        "\n",
        "    plt.figure(figsize=(7,4))\n",
        "    plt.plot(results[:,0], results[:,1], marker=\"o\", label=\"Subset Acc\")\n",
        "    plt.plot(results[:,0], results[:,2], marker=\"s\", label=\"Keras Binary Acc\")\n",
        "    for i, cname in enumerate(class_names):\n",
        "        plt.plot(results[:,0], results[:,3+i], marker=\".\", label=f\"Per-label Acc: {cname}\")\n",
        "    plt.title(f\"CNN-LSTM Attention {split_name} Threshold Sweep\")\n",
        "    plt.xlabel(\"Threshold\"); plt.ylabel(\"Accuracy\")\n",
        "    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    print(f\"Best subset-accuracy threshold for CNN-LSTM Attention {split_name}: {best['threshold']:.2f} (subset_acc={best['subset_acc']:.4f})\")\n",
        "    return results\n",
        "\n",
        "\n",
        "plot_history_cnn_lstm_attention(final_history)\n",
        "\n",
        "evaluate_split_cnn_lstm_attention(\"Final Test Set\", X_test, y_test, final_model, threshold=THRESHOLD)\n",
        "\n",
        "if DO_THRESHOLD_SWEEP:\n",
        "     print(\"\\nRunning Threshold Sweep for Final Test Set:\")\n",
        "     threshold_sweep_cnn_lstm_attention(\"Final Test Set\", X_test, y_test, final_model, CLASS_NAMES)\n",
        "\n",
        "print(\"\\n4-Class Confusion Matrix for Final Test Set:\")\n",
        "y_test_proba = final_model.predict(X_test)\n",
        "y_test_pred_bin = (y_test_proba >= THRESHOLD).astype(int)\n",
        "\n",
        "def get_4class_labels(y):\n",
        "    return np.array([\n",
        "        0 if (a == 0 and b == 0) else\n",
        "        1 if (a == 1 and b == 0) else\n",
        "        2 if (a == 0 and b == 1) else\n",
        "        3 for a, b in y\n",
        "    ])\n",
        "\n",
        "def plot_full_class_confusion_cnn(y_true_bin, y_pred_bin, split_name=\"\"):\n",
        "    y_true_single = get_4class_labels(y_true_bin)\n",
        "    y_pred_single = get_4class_labels(y_pred_bin)\n",
        "    cm_full = confusion_matrix(y_true_single, y_pred_single, labels=[0, 1, 2, 3])\n",
        "    class_labels = [\"Normal\", \"Crackles\", \"Wheezes\", \"Both\"]\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm_full, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.title(f\"CNN Model {split_name} — Confusion Matrix (4-Class View)\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return cm_full\n",
        "\n",
        "plot_full_class_confusion_cnn(y_test, y_test_pred_bin, split_name=\"Final Test Set\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e9b0ccb"
      },
      "source": [
        "### Final Tuned & Weighted CNN-LSTM Attention Model Summary of Findings\n",
        "\n",
        "Here is a summary of the final tuned and weighted CNN-LSTM Attention model's performance on the Test Set (using a threshold of 0.5):\n",
        "\n",
        "| Metric                     | Test Set (Overall) | Crackles (Test) | Wheezes (Test) |\n",
        "|----------------------------|--------------------|-----------------|----------------|\n",
        "| Keras Binary Accuracy      | 0.7531             | -               | -              |\n",
        "| Subset Accuracy            | 0.5671             | -               | -              |\n",
        "| Precision                  | -                  | 0.580           | 0.542          |\n",
        "| Recall                     | -                  | 0.295           | 0.293          |\n",
        "| F1-Score                   | -                  | 0.393           | 0.381          |\n",
        "| ROC AUC (Per-label)        | -                  | 0.687           | 0.715          |\n",
        "| ROC AUC (Micro-average)    | 0.715              | -               | -              |\n",
        "\n",
        "\n",
        "**Key Observations for the Final Tuned & Weighted Model:**\n",
        "\n",
        "*   **Impact of Tuning and Weighting:** Compared to the initial unweighted and untuned CNN-LSTM Attention model, this final model shows some improvements in certain areas on the test set. The Recall for both 'Crackles' (0.295 vs 0.185) and 'Wheezes' (0.293 vs 0.149) has increased, suggesting better identification of positive cases for both classes when the default 0.5 threshold is used. The F1-scores have also seen a modest improvement.\n",
        "*   **Precision vs. Recall Trade-off:** While recall improved, the precision for both classes (Crackles: 0.580, Wheezes: 0.542) is still relatively low, indicating that the model still produces a notable number of false positives.\n",
        "*   **Overall Accuracy:** The overall accuracy metrics (Keras Binary and Subset Accuracy) are still moderate, indicating that correctly classifying both labels simultaneously remains challenging.\n",
        "*   **ROC AUC:** The AUC values (Crackles: 0.687, Wheezes: 0.715, Micro-average: 0.715) provide a measure of the model's ability to distinguish between the classes across different thresholds. These values suggest that the model has some discriminatory power, but there is still significant room for improvement to reach the target AUC of 0.98.\n",
        "*   **Threshold Adjustment:** The threshold sweep plot for the test set shows that adjusting the threshold could potentially improve subset accuracy (best at threshold 0.60 with subset_acc=0.5826). However, this will likely involve trade-offs in precision and recall for individual classes.\n",
        "\n",
        "While hyperparameter tuning and class weighting have led to some improvements, particularly in recall for the minority class, the model's performance is still significantly below the target metrics (AUC of 0.98 and accuracy of 0.90).\n",
        "\n",
        "**Next Steps:**\n",
        "\n",
        "To further improve the model towards those ambitious targets, you could consider:\n",
        "\n",
        "1.  **Explore More Advanced Imbalance Handling:** Investigate techniques like more sophisticated oversampling methods or focusing the loss function more directly on improving minority class recall.\n",
        "2.  **Extensive Hyperparameter Tuning:** Run a more extensive hyperparameter search with a wider range of values or use more advanced tuning algorithms.\n",
        "3.  **Data Augmentation:** Implement audio data augmentation techniques.\n",
        "4.  **Explore Different Architectures:** Experiment with more powerful models designed for audio, potentially deeper CNNs, more complex LSTM or Transformer-based models, or different attention mechanisms.\n",
        "5.  **Feature Engineering:** Explore additional features or different ways of processing the audio data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e35467a2"
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "def add_noise(audio, noise_level=0.01):\n",
        "    \"\"\"Add random noise to the audio.\"\"\"\n",
        "    noise = np.random.randn(len(audio))\n",
        "    augmented_audio = audio + noise_level * noise\n",
        "    return augmented_audio\n",
        "\n",
        "def time_stretch(audio, rate=1.0):\n",
        "    \"\"\"Time-stretch the audio without changing pitch.\"\"\"\n",
        "\n",
        "    if rate == 1.0:\n",
        "        return audio\n",
        "\n",
        "    augmented_audio = librosa.effects.time_stretch(audio, rate=rate)\n",
        "    return augmented_audio\n",
        "\n",
        "def pitch_shift(audio, sr, n_steps):\n",
        "    \"\"\"Pitch-shift the audio.\"\"\"\n",
        "    augmented_audio = librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
        "    return augmented_audio\n",
        "\n",
        "def random_augment(audio, sr, noise_prob=0.5, time_stretch_prob=0.5, pitch_shift_prob=0.5):\n",
        "    \"\"\"Apply random augmentations with given probabilities.\"\"\"\n",
        "    augmented_audio = audio.copy()\n",
        "\n",
        "    if random.random() < noise_prob:\n",
        "        augmented_audio = add_noise(augmented_audio, noise_level=random.uniform(0.005, 0.02))\n",
        "\n",
        "    if random.random() < time_stretch_prob:\n",
        "\n",
        "        rate = random.uniform(0.8, 1.2)\n",
        "\n",
        "        augmented_audio = time_stretch(augmented_audio, rate=rate)\n",
        "\n",
        "\n",
        "    if random.random() < pitch_shift_prob:\n",
        "\n",
        "        n_steps = random.randint(-2, 2)\n",
        "        augmented_audio = pitch_shift(augmented_audio, sr=sr, n_steps=n_steps)\n",
        "\n",
        "\n",
        "    if len(augmented_audio) != len(audio):\n",
        "        if len(augmented_audio) > len(audio):\n",
        "            augmented_audio = augmented_audio[:len(audio)]\n",
        "        else:\n",
        "            # Pad with zeros\n",
        "            padding = np.zeros(len(audio) - len(augmented_audio))\n",
        "            augmented_audio = np.concatenate((augmented_audio, padding))\n",
        "\n",
        "\n",
        "    return augmented_audio\n",
        "\n",
        "print(\"Defined audio augmentation functions.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c18df450"
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "\n",
        "\n",
        "class AudioDataGenerator(Sequence):\n",
        "    def __init__(self, X_data, y_data, batch_size, sr, shuffle=True, augment=False):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        self.batch_size = batch_size\n",
        "        self.sr = sr\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.indices = np.arange(len(self.X_data))\n",
        "        if self.shuffle:\n",
        "            self.on_epoch_end() # Initial shuffle\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return int(np.floor(len(self.X_data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "\n",
        "        X_batch = self.X_data[batch_indices]\n",
        "        y_batch = self.y_data[batch_indices]\n",
        "\n",
        "\n",
        "        if self.augment:\n",
        "            augmented_X_batch = np.zeros_like(X_batch)\n",
        "            for i in range(X_batch.shape[0]):\n",
        "\n",
        "\n",
        "\n",
        "                if random.random() < 0.5:\n",
        "                     noise = np.random.uniform(-0.01, 0.01, size=X_batch[i].shape)\n",
        "                     augmented_X_batch[i] = X_batch[i] + noise\n",
        "\n",
        "                     augmented_X_batch[i] = np.clip(augmented_X_batch[i], X_batch[i].min(), X_batch[i].max())\n",
        "\n",
        "                else:\n",
        "                    augmented_X_batch[i] = X_batch[i]\n",
        "\n",
        "            X_batch = augmented_X_batch\n",
        "\n",
        "        return X_batch, y_batch\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "print(\"Defined AudioDataGenerator (with spectrogram noise augmentation for demonstration).\")\n",
        "print(\"Note: Implementing time/pitch shift on spectrograms directly is not standard. The ideal approach is augmenting raw audio before feature extraction.\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca64d23d"
      },
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Conv2D, MaxPooling2D, Dropout, Reshape,\n",
        "    Bidirectional, LSTM, Dense\n",
        ")\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_curve, auc,\n",
        "    accuracy_score, multilabel_confusion_matrix\n",
        ")\n",
        "\n",
        "\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        self.W = Dense(1, activation='tanh')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention = self.W(inputs)\n",
        "        attention = tf.nn.softmax(attention, axis=1)\n",
        "        context_vector = tf.reduce_sum(inputs * attention, axis=1)\n",
        "        return context_vector\n",
        "\n",
        "\n",
        "best_batch_size = best_hyperparameters['batch_size']\n",
        "\n",
        "TARGET_SR = 16000\n",
        "\n",
        "train_generator = AudioDataGenerator(X_train, y_train, batch_size=best_batch_size, sr=TARGET_SR, shuffle=True, augment=True)\n",
        "val_generator = AudioDataGenerator(X_val, y_val, batch_size=best_batch_size, sr=TARGET_SR, shuffle=False, augment=False)\n",
        "\n",
        "best_lr = best_hyperparameters['learning_rate']\n",
        "best_lstm_units = best_hyperparameters['lstm_units']\n",
        "best_dropout_dense = best_hyperparameters['dropout_dense']\n",
        "best_dense_units = best_hyperparameters['dense_units']\n",
        "\n",
        "\n",
        "model_augmented = Sequential([\n",
        "    Input(shape=(128, 157, 1)),\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Reshape((32, 39 * 64)),\n",
        "\n",
        "    Bidirectional(LSTM(best_lstm_units, return_sequences=True)),\n",
        "    AttentionLayer(),\n",
        "\n",
        "    Dense(best_dense_units, activation='relu'),\n",
        "    Dropout(best_dropout_dense),\n",
        "\n",
        "    Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=best_lr)\n",
        "model_augmented.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_augmented.summary()\n",
        "\n",
        "\n",
        "# --- Train Model with Generators ---\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "\n",
        "current_class_weight = class_weights_dict if USE_CLASS_WEIGHTS else None\n",
        "\n",
        "print(\"\\nTraining model with augmented data...\")\n",
        "history_augmented = model_augmented.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=100,\n",
        "    callbacks=[early_stop],\n",
        "    class_weight=current_class_weight,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "save_dir = '/content/ICBHI_extracted/ICBHI_final_database/processed_features'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "model_augmented_path = os.path.join(save_dir, 'cnn_lstm_attention_tuned_weighted_augmented_model.h5')\n",
        "model_augmented.save(model_augmented_path)\n",
        "print(f\" Tuned & Weighted CNN-LSTM Attention (Augmented) Model saved to: {model_augmented_path}\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nEvaluating augmented model on Test Set...\")\n",
        "\n",
        "\n",
        "plot_history_cnn_lstm_attention(history_augmented)\n",
        "\n",
        "\n",
        "evaluate_split_cnn_lstm_attention(\"Augmented Test Set\", X_test, y_test, model_augmented, threshold=THRESHOLD)\n",
        "\n",
        "\n",
        "if DO_THRESHOLD_SWEEP:\n",
        "     print(\"\\nRunning Threshold Sweep for Augmented Test Set:\")\n",
        "     threshold_sweep_cnn_lstm_attention(\"Augmented Test Set\", X_test, y_test, model_augmented, CLASS_NAMES)\n",
        "\n",
        "\n",
        "print(\"\\n4-Class Confusion Matrix for Augmented Test Set:\")\n",
        "y_test_proba = model_augmented.predict(X_test)\n",
        "y_test_pred_bin = (y_test_proba >= THRESHOLD).astype(int)\n",
        "\n",
        "def get_4class_labels(y):\n",
        "    return np.array([\n",
        "        0 if (a == 0 and b == 0) else\n",
        "        1 if (a == 1 and b == 0) else\n",
        "        2 if (a == 0 and b == 1) else\n",
        "        3 for a, b in y\n",
        "    ])\n",
        "\n",
        "def plot_full_class_confusion_cnn(y_true_bin, y_pred_bin, split_name=\"\"):\n",
        "    y_true_single = get_4class_labels(y_true_bin)\n",
        "    y_pred_single = get_4class_labels(y_pred_bin)\n",
        "    cm_full = confusion_matrix(y_true_single, y_pred_single, labels=[0, 1, 2, 3])\n",
        "    class_labels = [\"Normal\", \"Crackles\", \"Wheezes\", \"Both\"]\n",
        "\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm_full, annot=True, fmt=\"d\", cmap=\"Blues\", # Use Blues cmap\n",
        "                xticklabels=class_labels, yticklabels=class_labels)\n",
        "    plt.title(f\"CNN Model {split_name} — Confusion Matrix (4-Class View)\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    return cm_full\n",
        "\n",
        "plot_full_class_confusion_cnn(y_test, y_test_pred_bin, split_name=\"Augmented Test Set\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the test and validation splits for later use\n",
        "np.save(os.path.join(data_dir, 'X_test.npy'), X_test)\n",
        "np.save(os.path.join(data_dir, 'y_test.npy'), y_test)\n",
        "np.save(os.path.join(data_dir, 'X_val.npy'), X_val)\n",
        "np.save(os.path.join(data_dir, 'y_val.npy'), y_val)\n"
      ],
      "metadata": {
        "id": "ODfz3xbpBmOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install lime\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\n",
        "\n",
        "data_dir = '/content/ICBHI_extracted/ICBHI_final_database/processed_features'\n",
        "model_path = os.path.join(data_dir, 'cnn_lstm_attention_tuned_weighted_augmented_model.h5')\n",
        "\n",
        "\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        self.W = tf.keras.layers.Dense(1, activation='tanh')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attention = self.W(inputs)\n",
        "        attention = tf.nn.softmax(attention, axis=1)\n",
        "        context_vector = tf.reduce_sum(inputs * attention, axis=1)\n",
        "        return context_vector\n",
        "\n",
        "model = load_model(model_path, custom_objects={'AttentionLayer': AttentionLayer})\n",
        "print(\" Model loaded.\")\n",
        "\n",
        "\n",
        "X_test = np.load(os.path.join(data_dir, 'X_test.npy'))  # shape (num_samples, 128, 157, 1)\n",
        "sample_idx = 0\n",
        "img = X_test[sample_idx]  # shape (128, 157, 1)\n",
        "\n",
        "# Define prediction function for LIME\n",
        "def predict_fn(images):\n",
        "    \"\"\"\n",
        "    LIME sends RGB images, but your model expects grayscale (1 channel).\n",
        "    Convert RGB to grayscale by averaging channels and scale.\n",
        "    \"\"\"\n",
        "    images = np.array(images)\n",
        "    images_gray = np.mean(images, axis=-1, keepdims=True)  # Convert RGB -> grayscale (batch, h, w, 1)\n",
        "    images_gray = images_gray.astype('float32') / 255.0    # Normalize 0-1 (adjust if needed)\n",
        "    preds = model.predict(images_gray)\n",
        "    return preds\n",
        "\n",
        "# --- 3. Preprocess image for LIME ---\n",
        "def preprocess_for_lime(img):\n",
        "    \"\"\"\n",
        "    Input: grayscale image (128, 157, 1) with arbitrary range\n",
        "    Output: RGB uint8 image (128, 157, 3) scaled 0-255\n",
        "    \"\"\"\n",
        "    img = img.squeeze()\n",
        "    img_norm = (img - img.min()) / (img.max() - img.min())\n",
        "    img_uint8 = (img_norm * 255).astype(np.uint8)\n",
        "    img_rgb = np.stack([img_uint8]*3, axis=-1)  # grayscale to RGB (128, 157, 3)\n",
        "    return img_rgb\n",
        "\n",
        "lime_img = preprocess_for_lime(img)\n",
        "\n",
        "# --- 4. Create LIME explainer and explain for both classes ---\n",
        "explainer = lime_image.LimeImageExplainer()\n",
        "\n",
        "explanation = explainer.explain_instance(\n",
        "    lime_img,\n",
        "    predict_fn,\n",
        "    top_labels=2,\n",
        "    hide_color=0,\n",
        "    num_samples=1000\n",
        ")\n",
        "\n",
        "# --- 5. Plot LIME explanations for class 0 and class 1 side-by-side ---\n",
        "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "for i, class_id in enumerate([0, 1]):\n",
        "    temp, mask = explanation.get_image_and_mask(\n",
        "        label=class_id,\n",
        "        positive_only=True,\n",
        "        hide_rest=False,\n",
        "        num_features=10,\n",
        "        min_weight=0.05\n",
        "    )\n",
        "    axs[i].imshow(mark_boundaries(temp / 255.0, mask))\n",
        "    axs[i].set_title(f'LIME Explanation - Class {class_id}')\n",
        "    axs[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Yx66IpWmpqTj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}